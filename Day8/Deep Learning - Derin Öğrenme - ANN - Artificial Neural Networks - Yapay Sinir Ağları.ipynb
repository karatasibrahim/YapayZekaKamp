{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dde1e4e0",
   "metadata": {},
   "source": [
    "1- Tensorflow - KERAS - API kullanıyoruz.\n",
    "2- Tensor - Çok Boyutlu Matris Flow Google tarafından geliştirildi.\n",
    "3- Rakip - Facebook tarafından geliştirilen paket Pytorch\n",
    "4- GPU Grafik Ekran Kartları ile hesap yapmak daha hızlı\n",
    "5- Derin Öğrenme insan beyninin öğrenme şeklini kopyalamaktadır. İnsan beyni nasıl öğrenimişse yapay sinir ağları da aynı şekilde öğrenir.\n",
    "6- Nöronlar arasında gidip gelme işlemine EPOCH denir.\n",
    "7- Her nörondan diğerine bir ağırlık aktarılır. (katsayı)\n",
    "8- Aktarma işlemine Aktivasyon fonksiyonu karar verir. RELU, SOFTMAX, SİGMOİD\n",
    "9- Resimler çok büyük olduğu için parça - parça işlenir. Buna BATCH SİZE denir.\n",
    "10-Resimler üzerinde çalışıyorsak CNN kullanıyoruz.\n",
    "11-Resim,Text,Video üretme işlemlerini LSTM ile yapıyoruz. (Long-Short-Time Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203abdb",
   "metadata": {},
   "source": [
    "# Deep Learning ile Makine Öğrenmesi\n",
    "## Classification\n",
    "## Regression\n",
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99c3cc",
   "metadata": {},
   "source": [
    "1-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d24f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\ibrah\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\ibrah\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\ibrah\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af095587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf06dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a9ff2f",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deca7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0da1e9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ccee3b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be18f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e126a7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1a4cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16541f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[['Outcome']] #Hedefimiz şeker hastası olup olmadıklarını tespit edebilmek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184815c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df.iloc[:,0:8] yukarıdaki işlemin aynısı, daha pratik yazım şekli\n",
    "# y=df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8efb696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2b5624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,activation=\"relu\")) #8 nöron sayısı - Dense layer ekleiyoruz. Amacımız birinci nöronun ikinci layerda ki tüm nöronlara bağlanacağını belirtiyoruz.\n",
    "model.add(Dense(12,activation=\"relu\")) \n",
    "model.add(Dense(10,activation=\"relu\"))\n",
    "model.add(Dense(8,activation=\"relu\"))\n",
    "model.add(Dense(6,activation=\"relu\"))\n",
    "model.add(Dense(4,activation=\"relu\")) #üçüncü layer\n",
    "model.add(Dense(1,activation=\"sigmoid\")) #son layer ın aktivasyon fonksiyonu Sigmoid Evet veya Hayır cevabı dönecek\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b364d3ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 1s 1ms/step - loss: 10.4743 - accuracy: 0.4688\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.3953 - accuracy: 0.6328\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9879 - accuracy: 0.6367\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8559 - accuracy: 0.6445\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7822 - accuracy: 0.6406\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.6406\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.6419\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6523\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6576\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6641\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6641\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6654\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6641\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6641\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6641\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6667\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6641\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6654\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6654\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6628\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6641\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6667\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6654\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.6654\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6693\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6628\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6641\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6654\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6706\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6667\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6732\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6745\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6190 - accuracy: 0.6732\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6719\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6732\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.6784\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6823\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.6745\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6771\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6771\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6953\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6901\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5985 - accuracy: 0.6901\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.7018\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6992\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6940\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6901\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.7044\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6940\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.7148\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.7044\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.7018\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.7070\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7083\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7057\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7031\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7018\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.7174\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7096\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7188\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7148\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7201\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7135\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7201\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.7109\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7161\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7214\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7109\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7109\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7174\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7214\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7227\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7174\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7135\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7214\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7135\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7096\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7174\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7174\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7253\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7279\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7344\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7331\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7292\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7266\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7331\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7279\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7201\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.7148\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7253\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.7292\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7344\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7331\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7422\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7292\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7305\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.7240\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5486 - accuracy: 0.7383\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7305\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7344\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7357\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5462 - accuracy: 0.7331\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7357\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7396\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.7383\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7370\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7344\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7279\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5416 - accuracy: 0.7370\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.7435\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7370\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7357\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7383\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7448\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7344\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7383\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.7435\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7435\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7357\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7422\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7370\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.7422\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7526\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7435\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7422\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7461\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7292\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7422\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7344\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7487\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7396\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7435\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7357\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7383\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7227\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5219 - accuracy: 0.7331\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7500\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7526\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7500\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7409\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7422\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7435\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7500\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7396\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7357\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7435\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7565\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7487\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7461\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ac91fad60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=150,batch_size=10,verbose=1) #nöronlar arası gidip gelme işlemi epochs - yol\n",
    "#verbose=1 ile sonucunu aşağıda görebiliriz. Bir seferde batch_size=10 ile 10 ar satır alarak işlem yapar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a8b6298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a3072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7422\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y) #Başarı oranı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec46684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5139662623405457"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0] # başarısızlık oranı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc56ef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7421875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] #başarı oranı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c2c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping - 150 epoch  belirledik en uygun epoch un belirlenmesine Early epoch denilmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6704f631",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8078 - val_loss: 0.4928 - val_accuracy: 0.7727\n",
      "Epoch 2/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7948 - val_loss: 0.4971 - val_accuracy: 0.7403\n",
      "Epoch 3/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7850 - val_loss: 0.4900 - val_accuracy: 0.7662\n",
      "Epoch 4/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7932 - val_loss: 0.4892 - val_accuracy: 0.7597\n",
      "Epoch 5/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8062 - val_loss: 0.4887 - val_accuracy: 0.7532\n",
      "Epoch 6/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8029 - val_loss: 0.4935 - val_accuracy: 0.7468\n",
      "Epoch 7/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7948 - val_loss: 0.5059 - val_accuracy: 0.7532\n",
      "Epoch 8/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8046 - val_loss: 0.4801 - val_accuracy: 0.7468\n",
      "Epoch 9/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7932 - val_loss: 0.4872 - val_accuracy: 0.7532\n",
      "Epoch 10/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7980 - val_loss: 0.4836 - val_accuracy: 0.7532\n",
      "Epoch 11/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8046 - val_loss: 0.4696 - val_accuracy: 0.7532\n",
      "Epoch 12/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8078 - val_loss: 0.4852 - val_accuracy: 0.7597\n",
      "Epoch 13/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7948 - val_loss: 0.4847 - val_accuracy: 0.7468\n",
      "Epoch 14/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7948 - val_loss: 0.4996 - val_accuracy: 0.7597\n",
      "Epoch 15/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8013 - val_loss: 0.5175 - val_accuracy: 0.7468\n",
      "Epoch 16/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8127 - val_loss: 0.4908 - val_accuracy: 0.7662\n",
      "Epoch 17/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7915 - val_loss: 0.4904 - val_accuracy: 0.7922\n",
      "Epoch 18/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8111 - val_loss: 0.4613 - val_accuracy: 0.7662\n",
      "Epoch 19/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7964 - val_loss: 0.4754 - val_accuracy: 0.7727\n",
      "Epoch 20/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8013 - val_loss: 0.4729 - val_accuracy: 0.7662\n",
      "Epoch 21/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8046 - val_loss: 0.5079 - val_accuracy: 0.7727\n",
      "Epoch 22/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7932 - val_loss: 0.4917 - val_accuracy: 0.7597\n",
      "Epoch 23/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8062 - val_loss: 0.5511 - val_accuracy: 0.7597\n",
      "Epoch 24/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8029 - val_loss: 0.5209 - val_accuracy: 0.7532\n",
      "Epoch 25/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7964 - val_loss: 0.4951 - val_accuracy: 0.7532\n",
      "Epoch 26/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7883 - val_loss: 0.4795 - val_accuracy: 0.7532\n",
      "Epoch 27/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7948 - val_loss: 0.4865 - val_accuracy: 0.7597\n",
      "Epoch 28/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7997 - val_loss: 0.4879 - val_accuracy: 0.7597\n",
      "Epoch 29/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8029 - val_loss: 0.5193 - val_accuracy: 0.7468\n",
      "Epoch 30/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7850 - val_loss: 0.4852 - val_accuracy: 0.7662\n",
      "Epoch 31/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7850 - val_loss: 0.4951 - val_accuracy: 0.7532\n",
      "Epoch 32/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7997 - val_loss: 0.5340 - val_accuracy: 0.7468\n",
      "Epoch 33/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8029 - val_loss: 0.4784 - val_accuracy: 0.7662\n",
      "Epoch 34/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8029 - val_loss: 0.4915 - val_accuracy: 0.7857\n",
      "Epoch 35/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7932 - val_loss: 0.4775 - val_accuracy: 0.7662\n",
      "Epoch 36/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8094 - val_loss: 0.4827 - val_accuracy: 0.7792\n",
      "Epoch 37/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7997 - val_loss: 0.4936 - val_accuracy: 0.7532\n",
      "Epoch 38/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7915 - val_loss: 0.4991 - val_accuracy: 0.7662\n",
      "Epoch 39/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8062 - val_loss: 0.5105 - val_accuracy: 0.7597\n",
      "Epoch 40/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8062 - val_loss: 0.5082 - val_accuracy: 0.7597\n",
      "Epoch 41/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8013 - val_loss: 0.5038 - val_accuracy: 0.7662\n",
      "Epoch 42/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8046 - val_loss: 0.5093 - val_accuracy: 0.7403\n",
      "Epoch 43/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7980 - val_loss: 0.4883 - val_accuracy: 0.7532\n",
      "Epoch 44/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8013 - val_loss: 0.4873 - val_accuracy: 0.7662\n",
      "Epoch 45/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8013 - val_loss: 0.4806 - val_accuracy: 0.7597\n",
      "Epoch 46/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7964 - val_loss: 0.4852 - val_accuracy: 0.7468\n",
      "Epoch 47/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8029 - val_loss: 0.4872 - val_accuracy: 0.7662\n",
      "Epoch 48/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8013 - val_loss: 0.5005 - val_accuracy: 0.7532\n",
      "Epoch 49/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8013 - val_loss: 0.5122 - val_accuracy: 0.7532\n",
      "Epoch 50/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7980 - val_loss: 0.4972 - val_accuracy: 0.7662\n",
      "Epoch 51/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8013 - val_loss: 0.5156 - val_accuracy: 0.7662\n",
      "Epoch 52/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5044 - val_accuracy: 0.7403\n",
      "Epoch 53/54\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7964 - val_loss: 0.5279 - val_accuracy: 0.7403\n",
      "Epoch 54/54\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8062 - val_loss: 0.5278 - val_accuracy: 0.7468\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=54,validation_split=0.20,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46169461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cdb945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15ad3aedca0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"Val_Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c3b7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer sayısını artırmak \n",
    "#nöron sayısını artırmak\n",
    "#başarı sayısını artırır"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc16fffe",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ce1822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100) #tüm sütunları görmek için "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e875cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"kc_house.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfe3b0b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>price</th>\n",
       "      <th>zipcode_98002</th>\n",
       "      <th>zipcode_98003</th>\n",
       "      <th>zipcode_98004</th>\n",
       "      <th>zipcode_98005</th>\n",
       "      <th>zipcode_98006</th>\n",
       "      <th>zipcode_98007</th>\n",
       "      <th>zipcode_98008</th>\n",
       "      <th>zipcode_98010</th>\n",
       "      <th>zipcode_98011</th>\n",
       "      <th>zipcode_98014</th>\n",
       "      <th>zipcode_98019</th>\n",
       "      <th>zipcode_98022</th>\n",
       "      <th>zipcode_98023</th>\n",
       "      <th>zipcode_98024</th>\n",
       "      <th>zipcode_98027</th>\n",
       "      <th>zipcode_98028</th>\n",
       "      <th>zipcode_98029</th>\n",
       "      <th>zipcode_98030</th>\n",
       "      <th>zipcode_98031</th>\n",
       "      <th>zipcode_98032</th>\n",
       "      <th>zipcode_98033</th>\n",
       "      <th>zipcode_98034</th>\n",
       "      <th>zipcode_98038</th>\n",
       "      <th>zipcode_98039</th>\n",
       "      <th>zipcode_98040</th>\n",
       "      <th>zipcode_98042</th>\n",
       "      <th>zipcode_98045</th>\n",
       "      <th>zipcode_98052</th>\n",
       "      <th>zipcode_98053</th>\n",
       "      <th>zipcode_98055</th>\n",
       "      <th>zipcode_98056</th>\n",
       "      <th>zipcode_98058</th>\n",
       "      <th>zipcode_98059</th>\n",
       "      <th>zipcode_98065</th>\n",
       "      <th>zipcode_98070</th>\n",
       "      <th>zipcode_98072</th>\n",
       "      <th>zipcode_98074</th>\n",
       "      <th>zipcode_98075</th>\n",
       "      <th>zipcode_98077</th>\n",
       "      <th>zipcode_98092</th>\n",
       "      <th>zipcode_98102</th>\n",
       "      <th>zipcode_98103</th>\n",
       "      <th>zipcode_98105</th>\n",
       "      <th>zipcode_98106</th>\n",
       "      <th>zipcode_98107</th>\n",
       "      <th>zipcode_98108</th>\n",
       "      <th>zipcode_98109</th>\n",
       "      <th>zipcode_98112</th>\n",
       "      <th>zipcode_98115</th>\n",
       "      <th>zipcode_98116</th>\n",
       "      <th>zipcode_98117</th>\n",
       "      <th>zipcode_98118</th>\n",
       "      <th>zipcode_98119</th>\n",
       "      <th>zipcode_98122</th>\n",
       "      <th>zipcode_98125</th>\n",
       "      <th>zipcode_98126</th>\n",
       "      <th>zipcode_98133</th>\n",
       "      <th>zipcode_98136</th>\n",
       "      <th>zipcode_98144</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1180</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2170</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1050</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  condition  sqft_above     price  zipcode_98002  \\\n",
       "0     1.0   65          0          3        1180  221900.0              0   \n",
       "1     2.0   69          1          3        2170  538000.0              0   \n",
       "2     1.0   87          0          3         770  180000.0              0   \n",
       "3     1.0   55          0          5        1050  604000.0              0   \n",
       "4     1.0   33          0          3        1680  510000.0              0   \n",
       "\n",
       "   zipcode_98003  zipcode_98004  zipcode_98005  zipcode_98006  zipcode_98007  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98008  zipcode_98010  zipcode_98011  zipcode_98014  zipcode_98019  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98022  zipcode_98023  zipcode_98024  zipcode_98027  zipcode_98028  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              1   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98029  zipcode_98030  zipcode_98031  zipcode_98032  zipcode_98033  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98034  zipcode_98038  zipcode_98039  zipcode_98040  zipcode_98042  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98045  zipcode_98052  zipcode_98053  zipcode_98055  zipcode_98056  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98058  zipcode_98059  zipcode_98065  zipcode_98070  zipcode_98072  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98074  zipcode_98075  zipcode_98077  zipcode_98092  zipcode_98102  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   zipcode_98103  zipcode_98105  zipcode_98106  zipcode_98107  zipcode_98108  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98109  zipcode_98112  zipcode_98115  zipcode_98116  zipcode_98117  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98118  zipcode_98119  zipcode_98122  zipcode_98125  zipcode_98126  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98133  zipcode_98136  zipcode_98144  zipcode_98146  zipcode_98148  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  \\\n",
       "0              0              0              0              0              1   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb34eda8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        221900.0\n",
       "1        538000.0\n",
       "2        180000.0\n",
       "3        604000.0\n",
       "4        510000.0\n",
       "           ...   \n",
       "21608    360000.0\n",
       "21609    400000.0\n",
       "21610    402101.0\n",
       "21611    400000.0\n",
       "21612    325000.0\n",
       "Name: price, Length: 19034, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5c51625",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.drop(\"price\",axis=1) #price hariç diğer satırlar\n",
    "y=df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ab1f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a8b5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d33181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c53cfea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation=\"relu\")) #dense layer tüm nöronlar birbirine bağlanmış demektir.\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(19,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31a14689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10293156864.0000 - val_loss: 11042920448.0000\n",
      "Epoch 2/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10255865856.0000 - val_loss: 10959323136.0000\n",
      "Epoch 3/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10254069760.0000 - val_loss: 10931551232.0000\n",
      "Epoch 4/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10097565696.0000 - val_loss: 10822135808.0000\n",
      "Epoch 5/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10173770752.0000 - val_loss: 10848267264.0000\n",
      "Epoch 6/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10045498368.0000 - val_loss: 10872077312.0000\n",
      "Epoch 7/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10161168384.0000 - val_loss: 10757977088.0000\n",
      "Epoch 8/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10327053312.0000 - val_loss: 10693342208.0000\n",
      "Epoch 9/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9959143424.0000 - val_loss: 11132029952.0000\n",
      "Epoch 10/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10065897472.0000 - val_loss: 10763827200.0000\n",
      "Epoch 11/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10138118144.0000 - val_loss: 11189814272.0000\n",
      "Epoch 12/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9978405888.0000 - val_loss: 10590134272.0000\n",
      "Epoch 13/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10036247552.0000 - val_loss: 10581939200.0000\n",
      "Epoch 14/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10128917504.0000 - val_loss: 10667199488.0000\n",
      "Epoch 15/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9842976768.0000 - val_loss: 10950020096.0000\n",
      "Epoch 16/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10081568768.0000 - val_loss: 11465194496.0000\n",
      "Epoch 17/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9953858560.0000 - val_loss: 10546655232.0000\n",
      "Epoch 18/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 10037582848.0000 - val_loss: 10891843584.0000\n",
      "Epoch 19/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9837983744.0000 - val_loss: 10592872448.0000\n",
      "Epoch 20/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9788281856.0000 - val_loss: 10558472192.0000\n",
      "Epoch 21/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9820889088.0000 - val_loss: 10519585792.0000\n",
      "Epoch 22/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9937303552.0000 - val_loss: 10661229568.0000\n",
      "Epoch 23/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9778390016.0000 - val_loss: 10341021696.0000\n",
      "Epoch 24/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9750067200.0000 - val_loss: 10315650048.0000\n",
      "Epoch 25/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9641044992.0000 - val_loss: 10419593216.0000\n",
      "Epoch 26/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9608096768.0000 - val_loss: 10341352448.0000\n",
      "Epoch 27/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9588927488.0000 - val_loss: 10249653248.0000\n",
      "Epoch 28/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9634033664.0000 - val_loss: 10279087104.0000\n",
      "Epoch 29/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9638103040.0000 - val_loss: 10226657280.0000\n",
      "Epoch 30/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9596509184.0000 - val_loss: 11029369856.0000\n",
      "Epoch 31/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9669916672.0000 - val_loss: 10401883136.0000\n",
      "Epoch 32/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9594348544.0000 - val_loss: 10133274624.0000\n",
      "Epoch 33/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9549089792.0000 - val_loss: 10381743104.0000\n",
      "Epoch 34/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9670188032.0000 - val_loss: 10444248064.0000\n",
      "Epoch 35/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9635194880.0000 - val_loss: 10054353920.0000\n",
      "Epoch 36/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9866695680.0000 - val_loss: 10303492096.0000\n",
      "Epoch 37/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9495574528.0000 - val_loss: 10043230208.0000\n",
      "Epoch 38/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9410809856.0000 - val_loss: 10099791872.0000\n",
      "Epoch 39/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9523249152.0000 - val_loss: 9992148992.0000\n",
      "Epoch 40/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9526829056.0000 - val_loss: 10465542144.0000\n",
      "Epoch 41/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9385253888.0000 - val_loss: 10073518080.0000\n",
      "Epoch 42/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9358595072.0000 - val_loss: 10003865600.0000\n",
      "Epoch 43/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9471599616.0000 - val_loss: 10609437696.0000\n",
      "Epoch 44/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9415830528.0000 - val_loss: 10667147264.0000\n",
      "Epoch 45/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9318112256.0000 - val_loss: 9898235904.0000\n",
      "Epoch 46/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9301062656.0000 - val_loss: 10068595712.0000\n",
      "Epoch 47/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9338456064.0000 - val_loss: 9875799040.0000\n",
      "Epoch 48/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9292243968.0000 - val_loss: 9838265344.0000\n",
      "Epoch 49/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9275600896.0000 - val_loss: 9948225536.0000\n",
      "Epoch 50/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9592819712.0000 - val_loss: 9829070848.0000\n",
      "Epoch 51/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9315096576.0000 - val_loss: 10006137856.0000\n",
      "Epoch 52/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9473790976.0000 - val_loss: 10124832768.0000\n",
      "Epoch 53/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9389480960.0000 - val_loss: 9780360192.0000\n",
      "Epoch 54/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9209114624.0000 - val_loss: 10155916288.0000\n",
      "Epoch 55/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9161552896.0000 - val_loss: 9741636608.0000\n",
      "Epoch 56/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9290917888.0000 - val_loss: 9843527680.0000\n",
      "Epoch 57/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9322357760.0000 - val_loss: 9883707392.0000\n",
      "Epoch 58/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9405680640.0000 - val_loss: 10916109312.0000\n",
      "Epoch 59/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9291845632.0000 - val_loss: 9931376640.0000\n",
      "Epoch 60/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9171686400.0000 - val_loss: 9673738240.0000\n",
      "Epoch 61/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9098777600.0000 - val_loss: 9924143104.0000\n",
      "Epoch 62/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9242147840.0000 - val_loss: 9874664448.0000\n",
      "Epoch 63/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9015756800.0000 - val_loss: 10267751424.0000\n",
      "Epoch 64/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9148653568.0000 - val_loss: 10239063040.0000\n",
      "Epoch 65/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9026532352.0000 - val_loss: 9655442432.0000\n",
      "Epoch 66/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9171513344.0000 - val_loss: 9745913856.0000\n",
      "Epoch 67/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9049370624.0000 - val_loss: 9658136576.0000\n",
      "Epoch 68/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 9001833472.0000 - val_loss: 9589024768.0000\n",
      "Epoch 69/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9252173824.0000 - val_loss: 9565483008.0000\n",
      "Epoch 70/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9058917376.0000 - val_loss: 9825004544.0000\n",
      "Epoch 71/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9122077696.0000 - val_loss: 10065694720.0000\n",
      "Epoch 72/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9220970496.0000 - val_loss: 9773383680.0000\n",
      "Epoch 73/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9026633728.0000 - val_loss: 9972500480.0000\n",
      "Epoch 74/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8945745920.0000 - val_loss: 9590141952.0000\n",
      "Epoch 75/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9059246080.0000 - val_loss: 9514116096.0000\n",
      "Epoch 76/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9024031744.0000 - val_loss: 9583907840.0000\n",
      "Epoch 77/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8959056896.0000 - val_loss: 9677244416.0000\n",
      "Epoch 78/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8977289216.0000 - val_loss: 9552395264.0000\n",
      "Epoch 79/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 9004222464.0000 - val_loss: 9614953472.0000\n",
      "Epoch 80/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9126017024.0000 - val_loss: 9548491776.0000\n",
      "Epoch 81/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8895983616.0000 - val_loss: 9513607168.0000\n",
      "Epoch 82/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9054132224.0000 - val_loss: 9461765120.0000\n",
      "Epoch 83/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9030576128.0000 - val_loss: 9462885376.0000\n",
      "Epoch 84/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9099085824.0000 - val_loss: 9661147136.0000\n",
      "Epoch 85/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8962677760.0000 - val_loss: 9410258944.0000\n",
      "Epoch 86/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8911597568.0000 - val_loss: 10595771392.0000\n",
      "Epoch 87/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8993466368.0000 - val_loss: 9454845952.0000\n",
      "Epoch 88/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8898574336.0000 - val_loss: 9508497408.0000\n",
      "Epoch 89/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9091612672.0000 - val_loss: 9420023808.0000\n",
      "Epoch 90/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8930144256.0000 - val_loss: 9399622656.0000\n",
      "Epoch 91/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8887904256.0000 - val_loss: 9412065280.0000\n",
      "Epoch 92/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8918951936.0000 - val_loss: 9433697280.0000\n",
      "Epoch 93/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8863690752.0000 - val_loss: 9581733888.0000\n",
      "Epoch 94/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8824991744.0000 - val_loss: 9404857344.0000\n",
      "Epoch 95/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8762657792.0000 - val_loss: 9348014080.0000\n",
      "Epoch 96/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8872067072.0000 - val_loss: 9533924352.0000\n",
      "Epoch 97/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8739492864.0000 - val_loss: 9337048064.0000\n",
      "Epoch 98/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8897334272.0000 - val_loss: 9475238912.0000\n",
      "Epoch 99/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8787623936.0000 - val_loss: 9336035328.0000\n",
      "Epoch 100/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8813147136.0000 - val_loss: 9741229056.0000\n",
      "Epoch 101/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8935812096.0000 - val_loss: 9300280320.0000\n",
      "Epoch 102/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8963026944.0000 - val_loss: 9371196416.0000\n",
      "Epoch 103/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8680340480.0000 - val_loss: 10113211392.0000\n",
      "Epoch 104/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8808436736.0000 - val_loss: 9517064192.0000\n",
      "Epoch 105/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8761233408.0000 - val_loss: 9340209152.0000\n",
      "Epoch 106/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8659620864.0000 - val_loss: 9437635584.0000\n",
      "Epoch 107/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9011876864.0000 - val_loss: 9339128832.0000\n",
      "Epoch 108/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8668576768.0000 - val_loss: 9267254272.0000\n",
      "Epoch 109/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8880171008.0000 - val_loss: 9923063808.0000\n",
      "Epoch 110/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8723812352.0000 - val_loss: 9358163968.0000\n",
      "Epoch 111/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8824574976.0000 - val_loss: 9947078656.0000\n",
      "Epoch 112/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9013691392.0000 - val_loss: 10387211264.0000\n",
      "Epoch 113/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8779833344.0000 - val_loss: 9228499968.0000\n",
      "Epoch 114/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8854385664.0000 - val_loss: 9279788032.0000\n",
      "Epoch 115/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8650230784.0000 - val_loss: 9671610368.0000\n",
      "Epoch 116/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8858119168.0000 - val_loss: 9663428608.0000\n",
      "Epoch 117/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8844663808.0000 - val_loss: 9389667328.0000\n",
      "Epoch 118/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8703008768.0000 - val_loss: 9451295744.0000\n",
      "Epoch 119/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8590210048.0000 - val_loss: 9258933248.0000\n",
      "Epoch 120/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8705575936.0000 - val_loss: 9392115712.0000\n",
      "Epoch 121/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8801876992.0000 - val_loss: 9209736192.0000\n",
      "Epoch 122/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8669344768.0000 - val_loss: 9166831616.0000\n",
      "Epoch 123/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8689389568.0000 - val_loss: 9721314304.0000\n",
      "Epoch 124/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8608419840.0000 - val_loss: 9213172736.0000\n",
      "Epoch 125/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8582256128.0000 - val_loss: 9417059328.0000\n",
      "Epoch 126/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8596300800.0000 - val_loss: 9218557952.0000\n",
      "Epoch 127/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8591058944.0000 - val_loss: 9155804160.0000\n",
      "Epoch 128/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8646139904.0000 - val_loss: 9148729344.0000\n",
      "Epoch 129/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8669622272.0000 - val_loss: 9268425728.0000\n",
      "Epoch 130/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8575748608.0000 - val_loss: 9461604352.0000\n",
      "Epoch 131/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8556636160.0000 - val_loss: 10457662464.0000\n",
      "Epoch 132/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8725049344.0000 - val_loss: 9416993792.0000\n",
      "Epoch 133/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8723553280.0000 - val_loss: 9181157376.0000\n",
      "Epoch 134/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8484202496.0000 - val_loss: 9113682944.0000\n",
      "Epoch 135/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 8849305600.0000 - val_loss: 9117581312.0000\n",
      "Epoch 136/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8789483520.0000 - val_loss: 9916196864.0000\n",
      "Epoch 137/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8572846592.0000 - val_loss: 9404297216.0000\n",
      "Epoch 138/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8498368512.0000 - val_loss: 9279454208.0000\n",
      "Epoch 139/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8640808960.0000 - val_loss: 9465540608.0000\n",
      "Epoch 140/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8585795072.0000 - val_loss: 9676677120.0000\n",
      "Epoch 141/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8617888768.0000 - val_loss: 9130156032.0000\n",
      "Epoch 142/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8618524672.0000 - val_loss: 9616955392.0000\n",
      "Epoch 143/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8637619200.0000 - val_loss: 9212466176.0000\n",
      "Epoch 144/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8593287168.0000 - val_loss: 9346356224.0000\n",
      "Epoch 145/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8596832256.0000 - val_loss: 9258008576.0000\n",
      "Epoch 146/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8662973440.0000 - val_loss: 9061219328.0000\n",
      "Epoch 147/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8548819456.0000 - val_loss: 9122166784.0000\n",
      "Epoch 148/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8543228928.0000 - val_loss: 9144578048.0000\n",
      "Epoch 149/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8604098560.0000 - val_loss: 9062005760.0000\n",
      "Epoch 150/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8515146240.0000 - val_loss: 9660475392.0000\n",
      "Epoch 151/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8418673152.0000 - val_loss: 9186959360.0000\n",
      "Epoch 152/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8647494656.0000 - val_loss: 9107883008.0000\n",
      "Epoch 153/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8705432576.0000 - val_loss: 9511613440.0000\n",
      "Epoch 154/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8679751680.0000 - val_loss: 9147159552.0000\n",
      "Epoch 155/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8523862528.0000 - val_loss: 10512579584.0000\n",
      "Epoch 156/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8546302976.0000 - val_loss: 9123970048.0000\n",
      "Epoch 157/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8479403520.0000 - val_loss: 9669879808.0000\n",
      "Epoch 158/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8535754240.0000 - val_loss: 9477141504.0000\n",
      "Epoch 159/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8467216896.0000 - val_loss: 9275715584.0000\n",
      "Epoch 160/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8574699008.0000 - val_loss: 9039324160.0000\n",
      "Epoch 161/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8569670144.0000 - val_loss: 9023895552.0000\n",
      "Epoch 162/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8537644032.0000 - val_loss: 9027020800.0000\n",
      "Epoch 163/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8417729536.0000 - val_loss: 9106931712.0000\n",
      "Epoch 164/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8438241792.0000 - val_loss: 9017494528.0000\n",
      "Epoch 165/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8404042752.0000 - val_loss: 9238517760.0000\n",
      "Epoch 166/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8491887616.0000 - val_loss: 9522403328.0000\n",
      "Epoch 167/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8551145472.0000 - val_loss: 9542111232.0000\n",
      "Epoch 168/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8561358848.0000 - val_loss: 9020590080.0000\n",
      "Epoch 169/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8415285248.0000 - val_loss: 9050966016.0000\n",
      "Epoch 170/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8376356864.0000 - val_loss: 9009282048.0000\n",
      "Epoch 171/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8521044992.0000 - val_loss: 9030456320.0000\n",
      "Epoch 172/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8378614784.0000 - val_loss: 9338391552.0000\n",
      "Epoch 173/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8500407808.0000 - val_loss: 8952172544.0000\n",
      "Epoch 174/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8451981312.0000 - val_loss: 9498893312.0000\n",
      "Epoch 175/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8529670144.0000 - val_loss: 10014645248.0000\n",
      "Epoch 176/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8943364096.0000 - val_loss: 9483422720.0000\n",
      "Epoch 177/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8643787776.0000 - val_loss: 9081011200.0000\n",
      "Epoch 178/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8415122432.0000 - val_loss: 9018962944.0000\n",
      "Epoch 179/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8439251968.0000 - val_loss: 9198455808.0000\n",
      "Epoch 180/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8418074112.0000 - val_loss: 9198952448.0000\n",
      "Epoch 181/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8417220096.0000 - val_loss: 8973222912.0000\n",
      "Epoch 182/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8366759936.0000 - val_loss: 9046024192.0000\n",
      "Epoch 183/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8527708160.0000 - val_loss: 9614894080.0000\n",
      "Epoch 184/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8449980416.0000 - val_loss: 8947656704.0000\n",
      "Epoch 185/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8345304064.0000 - val_loss: 9009433600.0000\n",
      "Epoch 186/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8527796224.0000 - val_loss: 9056833536.0000\n",
      "Epoch 187/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8342756864.0000 - val_loss: 8921552896.0000\n",
      "Epoch 188/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8398855680.0000 - val_loss: 10395241472.0000\n",
      "Epoch 189/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8521262592.0000 - val_loss: 9062835200.0000\n",
      "Epoch 190/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8425296896.0000 - val_loss: 9302234112.0000\n",
      "Epoch 191/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8474567168.0000 - val_loss: 9211029504.0000\n",
      "Epoch 192/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8328592896.0000 - val_loss: 9017585664.0000\n",
      "Epoch 193/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8332068352.0000 - val_loss: 8938723328.0000\n",
      "Epoch 194/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8479366656.0000 - val_loss: 9289458688.0000\n",
      "Epoch 195/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8404262912.0000 - val_loss: 9675022336.0000\n",
      "Epoch 196/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8325436416.0000 - val_loss: 8902194176.0000\n",
      "Epoch 197/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8338424320.0000 - val_loss: 8947637248.0000\n",
      "Epoch 198/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8378225664.0000 - val_loss: 8946338816.0000\n",
      "Epoch 199/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8395950080.0000 - val_loss: 8940292096.0000\n",
      "Epoch 200/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8422141952.0000 - val_loss: 9036703744.0000\n",
      "Epoch 201/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8550428672.0000 - val_loss: 8924033024.0000\n",
      "Epoch 202/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 8607319040.0000 - val_loss: 9139153920.0000\n",
      "Epoch 203/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8320544768.0000 - val_loss: 8945259520.0000\n",
      "Epoch 204/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8321047040.0000 - val_loss: 9274385408.0000\n",
      "Epoch 205/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8359440896.0000 - val_loss: 9030667264.0000\n",
      "Epoch 206/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8312658432.0000 - val_loss: 9191768064.0000\n",
      "Epoch 207/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8393599488.0000 - val_loss: 9779136512.0000\n",
      "Epoch 208/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8403578880.0000 - val_loss: 9197769728.0000\n",
      "Epoch 209/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8326226944.0000 - val_loss: 9159868416.0000\n",
      "Epoch 210/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8314746368.0000 - val_loss: 8904766464.0000\n",
      "Epoch 211/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8409255936.0000 - val_loss: 9203351552.0000\n",
      "Epoch 212/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8583905280.0000 - val_loss: 8891004928.0000\n",
      "Epoch 213/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8375005696.0000 - val_loss: 9411956736.0000\n",
      "Epoch 214/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8377129472.0000 - val_loss: 9297961984.0000\n",
      "Epoch 215/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8345042944.0000 - val_loss: 8892901376.0000\n",
      "Epoch 216/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8320553984.0000 - val_loss: 9059489792.0000\n",
      "Epoch 217/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8348628480.0000 - val_loss: 8838875136.0000\n",
      "Epoch 218/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8369662976.0000 - val_loss: 8855285760.0000\n",
      "Epoch 219/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8275753984.0000 - val_loss: 8901414912.0000\n",
      "Epoch 220/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8482038784.0000 - val_loss: 8838088704.0000\n",
      "Epoch 221/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8457746432.0000 - val_loss: 9199209472.0000\n",
      "Epoch 222/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8518170624.0000 - val_loss: 9316570112.0000\n",
      "Epoch 223/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8301903872.0000 - val_loss: 14462023680.0000\n",
      "Epoch 224/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8706732032.0000 - val_loss: 8857186304.0000\n",
      "Epoch 225/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8233692672.0000 - val_loss: 9166148608.0000\n",
      "Epoch 226/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8296208384.0000 - val_loss: 8862334976.0000\n",
      "Epoch 227/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8317970432.0000 - val_loss: 9879565312.0000\n",
      "Epoch 228/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8436324864.0000 - val_loss: 9172897792.0000\n",
      "Epoch 229/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8315295232.0000 - val_loss: 8817430528.0000\n",
      "Epoch 230/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8392380416.0000 - val_loss: 8949613568.0000\n",
      "Epoch 231/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8304209920.0000 - val_loss: 8987487232.0000\n",
      "Epoch 232/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8349416960.0000 - val_loss: 8881610752.0000\n",
      "Epoch 233/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8282953728.0000 - val_loss: 8936028160.0000\n",
      "Epoch 234/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8228036096.0000 - val_loss: 8894746624.0000\n",
      "Epoch 235/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8190984704.0000 - val_loss: 9081318400.0000\n",
      "Epoch 236/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8219411456.0000 - val_loss: 8969489408.0000\n",
      "Epoch 237/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8205460480.0000 - val_loss: 8793742336.0000\n",
      "Epoch 238/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8233108992.0000 - val_loss: 8885688320.0000\n",
      "Epoch 239/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8304271872.0000 - val_loss: 8842226688.0000\n",
      "Epoch 240/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8281875968.0000 - val_loss: 9359486976.0000\n",
      "Epoch 241/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8256841728.0000 - val_loss: 9001523200.0000\n",
      "Epoch 242/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8210867712.0000 - val_loss: 8882294784.0000\n",
      "Epoch 243/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8211992576.0000 - val_loss: 9336721408.0000\n",
      "Epoch 244/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8634598400.0000 - val_loss: 8801960960.0000\n",
      "Epoch 245/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8173820416.0000 - val_loss: 8919876608.0000\n",
      "Epoch 246/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8138949120.0000 - val_loss: 8866298880.0000\n",
      "Epoch 247/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8219912192.0000 - val_loss: 8923943936.0000\n",
      "Epoch 248/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8152165888.0000 - val_loss: 8954637312.0000\n",
      "Epoch 249/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8237100032.0000 - val_loss: 9083281408.0000\n",
      "Epoch 250/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8259381248.0000 - val_loss: 9319233536.0000\n",
      "Epoch 251/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8249816576.0000 - val_loss: 8908162048.0000\n",
      "Epoch 252/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8272974848.0000 - val_loss: 8765961216.0000\n",
      "Epoch 253/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8173664256.0000 - val_loss: 8914683904.0000\n",
      "Epoch 254/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8261154816.0000 - val_loss: 9346683904.0000\n",
      "Epoch 255/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8257887744.0000 - val_loss: 9051226112.0000\n",
      "Epoch 256/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8154129920.0000 - val_loss: 8776018944.0000\n",
      "Epoch 257/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8499194368.0000 - val_loss: 8879575040.0000\n",
      "Epoch 258/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8241879040.0000 - val_loss: 8796883968.0000\n",
      "Epoch 259/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8351715328.0000 - val_loss: 8877481984.0000\n",
      "Epoch 260/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8211137024.0000 - val_loss: 8875443200.0000\n",
      "Epoch 261/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8383006208.0000 - val_loss: 8765284352.0000\n",
      "Epoch 262/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8242188800.0000 - val_loss: 8835942400.0000\n",
      "Epoch 263/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8260127744.0000 - val_loss: 8769853440.0000\n",
      "Epoch 264/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8097065984.0000 - val_loss: 8982628352.0000\n",
      "Epoch 265/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8247469568.0000 - val_loss: 9369399296.0000\n",
      "Epoch 266/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8361926656.0000 - val_loss: 8770606080.0000\n",
      "Epoch 267/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8089755136.0000 - val_loss: 8858933248.0000\n",
      "Epoch 268/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8233292800.0000 - val_loss: 8899111936.0000\n",
      "Epoch 269/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 8452424704.0000 - val_loss: 10186432512.0000\n",
      "Epoch 270/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8196184064.0000 - val_loss: 8813010944.0000\n",
      "Epoch 271/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8230647296.0000 - val_loss: 8823680000.0000\n",
      "Epoch 272/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8132338176.0000 - val_loss: 8899275776.0000\n",
      "Epoch 273/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8197458432.0000 - val_loss: 8841146368.0000\n",
      "Epoch 274/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8301236736.0000 - val_loss: 8959191040.0000\n",
      "Epoch 275/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8306503168.0000 - val_loss: 8908512256.0000\n",
      "Epoch 276/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8120919040.0000 - val_loss: 8741877760.0000\n",
      "Epoch 277/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8077521920.0000 - val_loss: 8813158400.0000\n",
      "Epoch 278/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8125678080.0000 - val_loss: 8844109824.0000\n",
      "Epoch 279/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8233525248.0000 - val_loss: 8793487360.0000\n",
      "Epoch 280/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8297575936.0000 - val_loss: 8857261056.0000\n",
      "Epoch 281/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8144463360.0000 - val_loss: 8721414144.0000\n",
      "Epoch 282/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8127475200.0000 - val_loss: 9048478720.0000\n",
      "Epoch 283/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8063380992.0000 - val_loss: 8886400000.0000\n",
      "Epoch 284/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8229374976.0000 - val_loss: 9252530176.0000\n",
      "Epoch 285/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8198595072.0000 - val_loss: 8807746560.0000\n",
      "Epoch 286/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8151600128.0000 - val_loss: 9654899712.0000\n",
      "Epoch 287/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8252691968.0000 - val_loss: 9065477120.0000\n",
      "Epoch 288/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8171550208.0000 - val_loss: 8988619776.0000\n",
      "Epoch 289/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8245324288.0000 - val_loss: 8795187200.0000\n",
      "Epoch 290/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8448565248.0000 - val_loss: 8719321088.0000\n",
      "Epoch 291/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8325756416.0000 - val_loss: 8730497024.0000\n",
      "Epoch 292/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8335707648.0000 - val_loss: 9222165504.0000\n",
      "Epoch 293/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8175518720.0000 - val_loss: 9256544256.0000\n",
      "Epoch 294/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8106604032.0000 - val_loss: 8735710208.0000\n",
      "Epoch 295/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8291128320.0000 - val_loss: 8859454464.0000\n",
      "Epoch 296/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8196474880.0000 - val_loss: 9285544960.0000\n",
      "Epoch 297/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8247545856.0000 - val_loss: 9397404672.0000\n",
      "Epoch 298/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8112502272.0000 - val_loss: 8798558208.0000\n",
      "Epoch 299/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8197463552.0000 - val_loss: 9026256896.0000\n",
      "Epoch 300/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8180301312.0000 - val_loss: 8719343616.0000\n",
      "Epoch 301/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8479426560.0000 - val_loss: 9045791744.0000\n",
      "Epoch 302/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8266171904.0000 - val_loss: 8795101184.0000\n",
      "Epoch 303/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8083289600.0000 - val_loss: 8723643392.0000\n",
      "Epoch 304/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8154485760.0000 - val_loss: 8796357632.0000\n",
      "Epoch 305/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8074030080.0000 - val_loss: 8950409216.0000\n",
      "Epoch 306/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8595289088.0000 - val_loss: 9992206336.0000\n",
      "Epoch 307/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8123519488.0000 - val_loss: 9113892864.0000\n",
      "Epoch 308/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8229747712.0000 - val_loss: 9182704640.0000\n",
      "Epoch 309/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8247051264.0000 - val_loss: 9269294080.0000\n",
      "Epoch 310/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8192109056.0000 - val_loss: 8747883520.0000\n",
      "Epoch 311/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8072528896.0000 - val_loss: 9096417280.0000\n",
      "Epoch 312/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8233653760.0000 - val_loss: 9628449792.0000\n",
      "Epoch 313/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8254592512.0000 - val_loss: 9083891712.0000\n",
      "Epoch 314/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7995519488.0000 - val_loss: 9064740864.0000\n",
      "Epoch 315/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8275890688.0000 - val_loss: 9803514880.0000\n",
      "Epoch 316/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8448101888.0000 - val_loss: 9015796736.0000\n",
      "Epoch 317/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8050793984.0000 - val_loss: 9203291136.0000\n",
      "Epoch 318/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8169598976.0000 - val_loss: 8858191872.0000\n",
      "Epoch 319/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8191383552.0000 - val_loss: 9034665984.0000\n",
      "Epoch 320/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8157225984.0000 - val_loss: 8775307264.0000\n",
      "Epoch 321/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8109985792.0000 - val_loss: 8668215296.0000\n",
      "Epoch 322/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8178810368.0000 - val_loss: 8665822208.0000\n",
      "Epoch 323/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8069749248.0000 - val_loss: 9004461056.0000\n",
      "Epoch 324/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8096922112.0000 - val_loss: 8860096512.0000\n",
      "Epoch 325/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8014852096.0000 - val_loss: 8825542656.0000\n",
      "Epoch 326/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8061787648.0000 - val_loss: 8727120896.0000\n",
      "Epoch 327/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8126196224.0000 - val_loss: 8737554432.0000\n",
      "Epoch 328/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8033110528.0000 - val_loss: 8725153792.0000\n",
      "Epoch 329/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8333206016.0000 - val_loss: 8687305728.0000\n",
      "Epoch 330/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8345400320.0000 - val_loss: 8818835456.0000\n",
      "Epoch 331/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8079731712.0000 - val_loss: 8987622400.0000\n",
      "Epoch 332/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8087546880.0000 - val_loss: 8643751936.0000\n",
      "Epoch 333/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8098580992.0000 - val_loss: 9152649216.0000\n",
      "Epoch 334/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8192833024.0000 - val_loss: 9660544000.0000\n",
      "Epoch 335/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8368372736.0000 - val_loss: 8820970496.0000\n",
      "Epoch 336/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 8021756416.0000 - val_loss: 8695768064.0000\n",
      "Epoch 337/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8106250752.0000 - val_loss: 9123440640.0000\n",
      "Epoch 338/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8060461568.0000 - val_loss: 8652916736.0000\n",
      "Epoch 339/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8095714304.0000 - val_loss: 8768201728.0000\n",
      "Epoch 340/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8304937472.0000 - val_loss: 8903950336.0000\n",
      "Epoch 341/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8094343680.0000 - val_loss: 8940426240.0000\n",
      "Epoch 342/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8120326144.0000 - val_loss: 9521534976.0000\n",
      "Epoch 343/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8082191360.0000 - val_loss: 8844251136.0000\n",
      "Epoch 344/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8053164544.0000 - val_loss: 8743836672.0000\n",
      "Epoch 345/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7939905024.0000 - val_loss: 8701422592.0000\n",
      "Epoch 346/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8079654912.0000 - val_loss: 8688569344.0000\n",
      "Epoch 347/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8035783680.0000 - val_loss: 8670502912.0000\n",
      "Epoch 348/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8008520704.0000 - val_loss: 8712111104.0000\n",
      "Epoch 349/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8184260096.0000 - val_loss: 8988887040.0000\n",
      "Epoch 350/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8171220992.0000 - val_loss: 8641445888.0000\n",
      "Epoch 351/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8095826432.0000 - val_loss: 8683196416.0000\n",
      "Epoch 352/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8055308800.0000 - val_loss: 8712600576.0000\n",
      "Epoch 353/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7991740928.0000 - val_loss: 8665464832.0000\n",
      "Epoch 354/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8010787328.0000 - val_loss: 8798849024.0000\n",
      "Epoch 355/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8002635776.0000 - val_loss: 8758251520.0000\n",
      "Epoch 356/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8114096640.0000 - val_loss: 8667390976.0000\n",
      "Epoch 357/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8155845120.0000 - val_loss: 8743099392.0000\n",
      "Epoch 358/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8019738624.0000 - val_loss: 8718097408.0000\n",
      "Epoch 359/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8128061952.0000 - val_loss: 9008837632.0000\n",
      "Epoch 360/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8019683328.0000 - val_loss: 9102307328.0000\n",
      "Epoch 361/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8071922688.0000 - val_loss: 8721458176.0000\n",
      "Epoch 362/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8292466688.0000 - val_loss: 9682022400.0000\n",
      "Epoch 363/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8082580480.0000 - val_loss: 8819751936.0000\n",
      "Epoch 364/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8119770624.0000 - val_loss: 9096382464.0000\n",
      "Epoch 365/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8058542080.0000 - val_loss: 9008654336.0000\n",
      "Epoch 366/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8068272128.0000 - val_loss: 8683069440.0000\n",
      "Epoch 367/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8163325440.0000 - val_loss: 8704598016.0000\n",
      "Epoch 368/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7993811456.0000 - val_loss: 8670236672.0000\n",
      "Epoch 369/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8005222912.0000 - val_loss: 9037131776.0000\n",
      "Epoch 370/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8222384128.0000 - val_loss: 8734474240.0000\n",
      "Epoch 371/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7911005184.0000 - val_loss: 8912348160.0000\n",
      "Epoch 372/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8104891392.0000 - val_loss: 8713824256.0000\n",
      "Epoch 373/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8208856064.0000 - val_loss: 10330049536.0000\n",
      "Epoch 374/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8090089472.0000 - val_loss: 8707051520.0000\n",
      "Epoch 375/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8124285440.0000 - val_loss: 8637297664.0000\n",
      "Epoch 376/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7977344512.0000 - val_loss: 8771284992.0000\n",
      "Epoch 377/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8113821184.0000 - val_loss: 9123652608.0000\n",
      "Epoch 378/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8021856768.0000 - val_loss: 8839811072.0000\n",
      "Epoch 379/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7991814144.0000 - val_loss: 8804944896.0000\n",
      "Epoch 380/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8159271936.0000 - val_loss: 9282510848.0000\n",
      "Epoch 381/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8096781824.0000 - val_loss: 8985107456.0000\n",
      "Epoch 382/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8005145600.0000 - val_loss: 8690194432.0000\n",
      "Epoch 383/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7968912384.0000 - val_loss: 8644935680.0000\n",
      "Epoch 384/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7986419712.0000 - val_loss: 8567715328.0000\n",
      "Epoch 385/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8111166464.0000 - val_loss: 9551378432.0000\n",
      "Epoch 386/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7940152832.0000 - val_loss: 8724410368.0000\n",
      "Epoch 387/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7896334848.0000 - val_loss: 8728750080.0000\n",
      "Epoch 388/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8017611776.0000 - val_loss: 8659752960.0000\n",
      "Epoch 389/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8022790656.0000 - val_loss: 9030486016.0000\n",
      "Epoch 390/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8109422592.0000 - val_loss: 9913001984.0000\n",
      "Epoch 391/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8045347840.0000 - val_loss: 9421016064.0000\n",
      "Epoch 392/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8118650368.0000 - val_loss: 8829980672.0000\n",
      "Epoch 393/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8048118784.0000 - val_loss: 8610026496.0000\n",
      "Epoch 394/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8060737024.0000 - val_loss: 8828797952.0000\n",
      "Epoch 395/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8050914304.0000 - val_loss: 8765869056.0000\n",
      "Epoch 396/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7904795648.0000 - val_loss: 8687810560.0000\n",
      "Epoch 397/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7963060736.0000 - val_loss: 9677111296.0000\n",
      "Epoch 398/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8107421696.0000 - val_loss: 11106366464.0000\n",
      "Epoch 399/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8162147328.0000 - val_loss: 8820685824.0000\n",
      "Epoch 400/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8167379456.0000 - val_loss: 8672479232.0000\n",
      "Epoch 401/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7834442240.0000 - val_loss: 8594638848.0000\n",
      "Epoch 402/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7965414912.0000 - val_loss: 8774998016.0000\n",
      "Epoch 403/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 8007463424.0000 - val_loss: 8730046464.0000\n",
      "Epoch 404/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8086323712.0000 - val_loss: 8716770304.0000\n",
      "Epoch 405/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7939104256.0000 - val_loss: 8855713792.0000\n",
      "Epoch 406/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7939834368.0000 - val_loss: 9179198464.0000\n",
      "Epoch 407/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7986051584.0000 - val_loss: 9246788608.0000\n",
      "Epoch 408/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8120147456.0000 - val_loss: 8588349952.0000\n",
      "Epoch 409/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7912645632.0000 - val_loss: 8698512384.0000\n",
      "Epoch 410/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8109092864.0000 - val_loss: 9041115136.0000\n",
      "Epoch 411/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8187414016.0000 - val_loss: 8520899584.0000\n",
      "Epoch 412/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8161818624.0000 - val_loss: 8802538496.0000\n",
      "Epoch 413/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8075102208.0000 - val_loss: 8982212608.0000\n",
      "Epoch 414/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7873387520.0000 - val_loss: 8578994176.0000\n",
      "Epoch 415/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7916111360.0000 - val_loss: 8645857280.0000\n",
      "Epoch 416/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8036068352.0000 - val_loss: 9307257856.0000\n",
      "Epoch 417/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8069695488.0000 - val_loss: 8704672768.0000\n",
      "Epoch 418/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7923010560.0000 - val_loss: 8980466688.0000\n",
      "Epoch 419/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7989004800.0000 - val_loss: 8640551936.0000\n",
      "Epoch 420/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8077149184.0000 - val_loss: 9021608960.0000\n",
      "Epoch 421/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7957168640.0000 - val_loss: 8592279552.0000\n",
      "Epoch 422/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7868663296.0000 - val_loss: 8564633088.0000\n",
      "Epoch 423/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8181939712.0000 - val_loss: 9871876096.0000\n",
      "Epoch 424/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7984081920.0000 - val_loss: 9496278016.0000\n",
      "Epoch 425/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7852794880.0000 - val_loss: 9049180160.0000\n",
      "Epoch 426/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7982066176.0000 - val_loss: 8715437056.0000\n",
      "Epoch 427/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7949604864.0000 - val_loss: 8784618496.0000\n",
      "Epoch 428/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7870946304.0000 - val_loss: 9095752704.0000\n",
      "Epoch 429/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8072968192.0000 - val_loss: 8606876672.0000\n",
      "Epoch 430/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8263597056.0000 - val_loss: 8583805440.0000\n",
      "Epoch 431/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7977538048.0000 - val_loss: 8587312640.0000\n",
      "Epoch 432/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7920504832.0000 - val_loss: 9411640320.0000\n",
      "Epoch 433/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7996559360.0000 - val_loss: 8651424768.0000\n",
      "Epoch 434/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8100652032.0000 - val_loss: 9501026304.0000\n",
      "Epoch 435/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8100831744.0000 - val_loss: 8616517632.0000\n",
      "Epoch 436/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7910307840.0000 - val_loss: 8602270720.0000\n",
      "Epoch 437/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8162632192.0000 - val_loss: 8534688768.0000\n",
      "Epoch 438/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8036897792.0000 - val_loss: 8506536960.0000\n",
      "Epoch 439/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7884070400.0000 - val_loss: 8991298560.0000\n",
      "Epoch 440/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7913692672.0000 - val_loss: 8589762048.0000\n",
      "Epoch 441/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7857063424.0000 - val_loss: 8539850240.0000\n",
      "Epoch 442/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8038153728.0000 - val_loss: 8910775296.0000\n",
      "Epoch 443/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8322205184.0000 - val_loss: 8720710656.0000\n",
      "Epoch 444/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7961932800.0000 - val_loss: 8523454976.0000\n",
      "Epoch 445/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8134669824.0000 - val_loss: 8507201536.0000\n",
      "Epoch 446/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8078466560.0000 - val_loss: 8601548800.0000\n",
      "Epoch 447/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7859677184.0000 - val_loss: 8663133184.0000\n",
      "Epoch 448/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7888254464.0000 - val_loss: 8500293120.0000\n",
      "Epoch 449/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7786380288.0000 - val_loss: 9130998784.0000\n",
      "Epoch 450/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7978564096.0000 - val_loss: 8576083968.0000\n",
      "Epoch 451/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7969012224.0000 - val_loss: 8543185920.0000\n",
      "Epoch 452/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7756699648.0000 - val_loss: 8567127552.0000\n",
      "Epoch 453/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8124515328.0000 - val_loss: 8712895488.0000\n",
      "Epoch 454/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7905146880.0000 - val_loss: 8698997760.0000\n",
      "Epoch 455/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7896351232.0000 - val_loss: 8510036992.0000\n",
      "Epoch 456/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7873265152.0000 - val_loss: 8521323008.0000\n",
      "Epoch 457/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7905362432.0000 - val_loss: 8566998016.0000\n",
      "Epoch 458/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7952039424.0000 - val_loss: 8775193600.0000\n",
      "Epoch 459/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7901391360.0000 - val_loss: 8676426752.0000\n",
      "Epoch 460/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7871468544.0000 - val_loss: 8763602944.0000\n",
      "Epoch 461/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8090958848.0000 - val_loss: 9041126400.0000\n",
      "Epoch 462/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7938990080.0000 - val_loss: 8817351680.0000\n",
      "Epoch 463/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7838487552.0000 - val_loss: 8868218880.0000\n",
      "Epoch 464/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7917437440.0000 - val_loss: 8533122048.0000\n",
      "Epoch 465/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7806401024.0000 - val_loss: 8522973696.0000\n",
      "Epoch 466/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7901062656.0000 - val_loss: 8759906304.0000\n",
      "Epoch 467/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7860414464.0000 - val_loss: 8856061952.0000\n",
      "Epoch 468/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8047150080.0000 - val_loss: 8721772544.0000\n",
      "Epoch 469/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7875928064.0000 - val_loss: 8748466176.0000\n",
      "Epoch 470/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7915334144.0000 - val_loss: 8556744192.0000\n",
      "Epoch 471/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7922013696.0000 - val_loss: 8626482176.0000\n",
      "Epoch 472/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7877386240.0000 - val_loss: 8819421184.0000\n",
      "Epoch 473/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7903931904.0000 - val_loss: 8458906624.0000\n",
      "Epoch 474/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7835729920.0000 - val_loss: 8610830336.0000\n",
      "Epoch 475/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8134271488.0000 - val_loss: 8557658112.0000\n",
      "Epoch 476/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7982227456.0000 - val_loss: 8541263360.0000\n",
      "Epoch 477/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7888759808.0000 - val_loss: 8481738240.0000\n",
      "Epoch 478/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7888500736.0000 - val_loss: 9200177152.0000\n",
      "Epoch 479/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8044240896.0000 - val_loss: 8484227072.0000\n",
      "Epoch 480/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7777454592.0000 - val_loss: 8738538496.0000\n",
      "Epoch 481/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7902685696.0000 - val_loss: 8664248320.0000\n",
      "Epoch 482/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7897224192.0000 - val_loss: 8910602240.0000\n",
      "Epoch 483/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7889179136.0000 - val_loss: 8587661824.0000\n",
      "Epoch 484/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7999351808.0000 - val_loss: 8714433536.0000\n",
      "Epoch 485/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7953017856.0000 - val_loss: 8533106176.0000\n",
      "Epoch 486/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7931579392.0000 - val_loss: 8573496832.0000\n",
      "Epoch 487/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7902951936.0000 - val_loss: 8898981888.0000\n",
      "Epoch 488/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8116160000.0000 - val_loss: 8594681856.0000\n",
      "Epoch 489/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7873240064.0000 - val_loss: 8603640832.0000\n",
      "Epoch 490/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7803123200.0000 - val_loss: 8673967104.0000\n",
      "Epoch 491/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7863468032.0000 - val_loss: 8767843328.0000\n",
      "Epoch 492/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7794624512.0000 - val_loss: 9186625536.0000\n",
      "Epoch 493/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8009878016.0000 - val_loss: 8810420224.0000\n",
      "Epoch 494/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7884915712.0000 - val_loss: 8764064768.0000\n",
      "Epoch 495/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7903217152.0000 - val_loss: 8684174336.0000\n",
      "Epoch 496/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7801135616.0000 - val_loss: 8586817536.0000\n",
      "Epoch 497/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7764892160.0000 - val_loss: 8484040192.0000\n",
      "Epoch 498/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7926862848.0000 - val_loss: 8511686656.0000\n",
      "Epoch 499/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8193276416.0000 - val_loss: 9225907200.0000\n",
      "Epoch 500/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7774247424.0000 - val_loss: 8614115328.0000\n",
      "Epoch 501/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7772895232.0000 - val_loss: 8488145408.0000\n",
      "Epoch 502/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7927088128.0000 - val_loss: 8677028864.0000\n",
      "Epoch 503/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7858743296.0000 - val_loss: 8502542336.0000\n",
      "Epoch 504/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7863110144.0000 - val_loss: 8562544128.0000\n",
      "Epoch 505/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7944183808.0000 - val_loss: 8557812224.0000\n",
      "Epoch 506/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7832402432.0000 - val_loss: 8583980032.0000\n",
      "Epoch 507/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8086483456.0000 - val_loss: 8905981952.0000\n",
      "Epoch 508/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7726210560.0000 - val_loss: 8502007296.0000\n",
      "Epoch 509/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7905284608.0000 - val_loss: 8625589248.0000\n",
      "Epoch 510/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7772176384.0000 - val_loss: 8474501120.0000\n",
      "Epoch 511/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8021713408.0000 - val_loss: 8466637312.0000\n",
      "Epoch 512/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7866402304.0000 - val_loss: 8646057984.0000\n",
      "Epoch 513/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7904462336.0000 - val_loss: 9326065664.0000\n",
      "Epoch 514/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7832277504.0000 - val_loss: 9179195392.0000\n",
      "Epoch 515/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8107454464.0000 - val_loss: 8680750080.0000\n",
      "Epoch 516/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7747521536.0000 - val_loss: 8693410816.0000\n",
      "Epoch 517/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7759921152.0000 - val_loss: 8511679488.0000\n",
      "Epoch 518/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7873286656.0000 - val_loss: 8479519744.0000\n",
      "Epoch 519/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7879749120.0000 - val_loss: 10163393536.0000\n",
      "Epoch 520/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8006167040.0000 - val_loss: 8529458176.0000\n",
      "Epoch 521/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7838608896.0000 - val_loss: 8593734656.0000\n",
      "Epoch 522/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7929307648.0000 - val_loss: 8653688832.0000\n",
      "Epoch 523/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8112751104.0000 - val_loss: 8565192704.0000\n",
      "Epoch 524/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7820748288.0000 - val_loss: 8565075456.0000\n",
      "Epoch 525/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7906940416.0000 - val_loss: 10283432960.0000\n",
      "Epoch 526/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7867130880.0000 - val_loss: 8509969408.0000\n",
      "Epoch 527/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7721244672.0000 - val_loss: 9456970752.0000\n",
      "Epoch 528/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8098662912.0000 - val_loss: 8427197440.0000\n",
      "Epoch 529/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7923220480.0000 - val_loss: 9583253504.0000\n",
      "Epoch 530/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7924972544.0000 - val_loss: 8638479360.0000\n",
      "Epoch 531/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7782341120.0000 - val_loss: 8719217664.0000\n",
      "Epoch 532/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7928609280.0000 - val_loss: 8622623744.0000\n",
      "Epoch 533/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7866486784.0000 - val_loss: 8735293440.0000\n",
      "Epoch 534/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7819310592.0000 - val_loss: 8473731584.0000\n",
      "Epoch 535/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7880464896.0000 - val_loss: 9095302144.0000\n",
      "Epoch 536/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7768165376.0000 - val_loss: 8805644288.0000\n",
      "Epoch 537/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7910109696.0000 - val_loss: 8557523456.0000\n",
      "Epoch 538/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7875045376.0000 - val_loss: 9476946944.0000\n",
      "Epoch 539/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8069919232.0000 - val_loss: 9424099328.0000\n",
      "Epoch 540/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8095061504.0000 - val_loss: 8600040448.0000\n",
      "Epoch 541/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8000434688.0000 - val_loss: 8522137600.0000\n",
      "Epoch 542/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7811985408.0000 - val_loss: 8422642688.0000\n",
      "Epoch 543/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7812380160.0000 - val_loss: 8613579776.0000\n",
      "Epoch 544/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7787600384.0000 - val_loss: 8567104000.0000\n",
      "Epoch 545/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7808155136.0000 - val_loss: 8711667712.0000\n",
      "Epoch 546/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7926083072.0000 - val_loss: 9079426048.0000\n",
      "Epoch 547/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7761434624.0000 - val_loss: 8618299392.0000\n",
      "Epoch 548/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7916894720.0000 - val_loss: 8742579200.0000\n",
      "Epoch 549/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7798255616.0000 - val_loss: 8459696640.0000\n",
      "Epoch 550/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7803164160.0000 - val_loss: 8376235008.0000\n",
      "Epoch 551/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7826126336.0000 - val_loss: 8387388416.0000\n",
      "Epoch 552/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7939910144.0000 - val_loss: 8551228928.0000\n",
      "Epoch 553/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7841494016.0000 - val_loss: 8476401152.0000\n",
      "Epoch 554/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7706427904.0000 - val_loss: 8487826944.0000\n",
      "Epoch 555/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7890677248.0000 - val_loss: 8423816192.0000\n",
      "Epoch 556/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7811623936.0000 - val_loss: 8780577792.0000\n",
      "Epoch 557/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7757575168.0000 - val_loss: 8637748224.0000\n",
      "Epoch 558/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7988285440.0000 - val_loss: 9997248512.0000\n",
      "Epoch 559/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7921536512.0000 - val_loss: 8583365120.0000\n",
      "Epoch 560/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7816499712.0000 - val_loss: 8690693120.0000\n",
      "Epoch 561/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7788379648.0000 - val_loss: 8394691584.0000\n",
      "Epoch 562/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7753939968.0000 - val_loss: 8593107968.0000\n",
      "Epoch 563/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7730933760.0000 - val_loss: 8514634240.0000\n",
      "Epoch 564/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7812210688.0000 - val_loss: 9096111104.0000\n",
      "Epoch 565/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7914190336.0000 - val_loss: 9032182784.0000\n",
      "Epoch 566/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7795489792.0000 - val_loss: 8376244224.0000\n",
      "Epoch 567/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7801205760.0000 - val_loss: 8471586304.0000\n",
      "Epoch 568/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7923103232.0000 - val_loss: 8865267712.0000\n",
      "Epoch 569/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7910940160.0000 - val_loss: 8754476032.0000\n",
      "Epoch 570/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7746250240.0000 - val_loss: 8457098752.0000\n",
      "Epoch 571/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7867149312.0000 - val_loss: 9908800512.0000\n",
      "Epoch 572/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7949898752.0000 - val_loss: 8406283776.0000\n",
      "Epoch 573/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7952782848.0000 - val_loss: 8653902848.0000\n",
      "Epoch 574/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7789564416.0000 - val_loss: 9159330816.0000\n",
      "Epoch 575/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7890069504.0000 - val_loss: 9032622080.0000\n",
      "Epoch 576/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7975141888.0000 - val_loss: 8417372160.0000\n",
      "Epoch 577/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7724530688.0000 - val_loss: 8948193280.0000\n",
      "Epoch 578/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7931340800.0000 - val_loss: 9015362560.0000\n",
      "Epoch 579/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7972836352.0000 - val_loss: 8575713792.0000\n",
      "Epoch 580/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7870998016.0000 - val_loss: 8397575168.0000\n",
      "Epoch 581/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7624029184.0000 - val_loss: 8395708928.0000\n",
      "Epoch 582/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8046267904.0000 - val_loss: 8384662528.0000\n",
      "Epoch 583/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7691331072.0000 - val_loss: 8420097536.0000\n",
      "Epoch 584/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7669252096.0000 - val_loss: 8406116864.0000\n",
      "Epoch 585/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7906971136.0000 - val_loss: 9169550336.0000\n",
      "Epoch 586/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7861208064.0000 - val_loss: 9809001472.0000\n",
      "Epoch 587/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7830722560.0000 - val_loss: 8672454656.0000\n",
      "Epoch 588/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7772471808.0000 - val_loss: 8555126272.0000\n",
      "Epoch 589/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7606670336.0000 - val_loss: 8868762624.0000\n",
      "Epoch 590/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7778893824.0000 - val_loss: 8441670144.0000\n",
      "Epoch 591/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7762743808.0000 - val_loss: 8449598976.0000\n",
      "Epoch 592/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7669658624.0000 - val_loss: 8430660096.0000\n",
      "Epoch 593/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7711476736.0000 - val_loss: 8426492928.0000\n",
      "Epoch 594/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8057317376.0000 - val_loss: 9623196672.0000\n",
      "Epoch 595/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7821662208.0000 - val_loss: 8594245632.0000\n",
      "Epoch 596/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7813499904.0000 - val_loss: 8613582848.0000\n",
      "Epoch 597/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7788702208.0000 - val_loss: 8405550592.0000\n",
      "Epoch 598/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7748506624.0000 - val_loss: 8456676352.0000\n",
      "Epoch 599/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7676430848.0000 - val_loss: 8815602688.0000\n",
      "Epoch 600/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7800886272.0000 - val_loss: 9634713600.0000\n",
      "Epoch 601/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7770231296.0000 - val_loss: 8816287744.0000\n",
      "Epoch 602/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7805028352.0000 - val_loss: 9301847040.0000\n",
      "Epoch 603/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7733302272.0000 - val_loss: 8327421952.0000\n",
      "Epoch 604/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7803661312.0000 - val_loss: 8379922432.0000\n",
      "Epoch 605/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7769424384.0000 - val_loss: 8381358592.0000\n",
      "Epoch 606/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7751772672.0000 - val_loss: 8346663424.0000\n",
      "Epoch 607/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7629031936.0000 - val_loss: 8490860544.0000\n",
      "Epoch 608/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7792349696.0000 - val_loss: 8368473600.0000\n",
      "Epoch 609/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7846662656.0000 - val_loss: 8424875008.0000\n",
      "Epoch 610/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7887489536.0000 - val_loss: 8456833536.0000\n",
      "Epoch 611/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7707888128.0000 - val_loss: 8865551360.0000\n",
      "Epoch 612/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7845787648.0000 - val_loss: 8380603392.0000\n",
      "Epoch 613/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7673531904.0000 - val_loss: 9357079552.0000\n",
      "Epoch 614/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7705417728.0000 - val_loss: 8568414208.0000\n",
      "Epoch 615/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7880574464.0000 - val_loss: 8664690688.0000\n",
      "Epoch 616/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7736665600.0000 - val_loss: 8572375552.0000\n",
      "Epoch 617/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7810329088.0000 - val_loss: 8715531264.0000\n",
      "Epoch 618/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7962188288.0000 - val_loss: 8430056960.0000\n",
      "Epoch 619/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7935198208.0000 - val_loss: 8414074368.0000\n",
      "Epoch 620/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7864844800.0000 - val_loss: 8352978432.0000\n",
      "Epoch 621/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7676188672.0000 - val_loss: 8319855104.0000\n",
      "Epoch 622/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7806720000.0000 - val_loss: 8306429440.0000\n",
      "Epoch 623/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7750204928.0000 - val_loss: 8379954176.0000\n",
      "Epoch 624/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7611326976.0000 - val_loss: 8756515840.0000\n",
      "Epoch 625/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7762946560.0000 - val_loss: 8404275712.0000\n",
      "Epoch 626/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7725207552.0000 - val_loss: 8311084544.0000\n",
      "Epoch 627/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7806090752.0000 - val_loss: 8560375808.0000\n",
      "Epoch 628/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7700008448.0000 - val_loss: 8369488896.0000\n",
      "Epoch 629/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7869138944.0000 - val_loss: 8948222976.0000\n",
      "Epoch 630/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8142997504.0000 - val_loss: 9897338880.0000\n",
      "Epoch 631/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7785315840.0000 - val_loss: 8694990848.0000\n",
      "Epoch 632/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7637791744.0000 - val_loss: 8587453440.0000\n",
      "Epoch 633/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7763557376.0000 - val_loss: 8753792000.0000\n",
      "Epoch 634/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7655764480.0000 - val_loss: 8455490048.0000\n",
      "Epoch 635/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7667542528.0000 - val_loss: 8388468224.0000\n",
      "Epoch 636/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7670201856.0000 - val_loss: 9001206784.0000\n",
      "Epoch 637/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7928558592.0000 - val_loss: 8412689920.0000\n",
      "Epoch 638/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7872592896.0000 - val_loss: 8717006848.0000\n",
      "Epoch 639/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7768280576.0000 - val_loss: 8412170240.0000\n",
      "Epoch 640/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7668619264.0000 - val_loss: 8409300480.0000\n",
      "Epoch 641/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7680133632.0000 - val_loss: 10098081792.0000\n",
      "Epoch 642/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7797442048.0000 - val_loss: 8423254016.0000\n",
      "Epoch 643/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7684253696.0000 - val_loss: 8551126528.0000\n",
      "Epoch 644/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7795426816.0000 - val_loss: 8395986944.0000\n",
      "Epoch 645/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7731233792.0000 - val_loss: 8735287296.0000\n",
      "Epoch 646/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7690244096.0000 - val_loss: 8450788352.0000\n",
      "Epoch 647/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7722427392.0000 - val_loss: 8876619776.0000\n",
      "Epoch 648/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7769571328.0000 - val_loss: 8389603840.0000\n",
      "Epoch 649/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7821277696.0000 - val_loss: 9174512640.0000\n",
      "Epoch 650/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7691355648.0000 - val_loss: 8404357120.0000\n",
      "Epoch 651/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7926197248.0000 - val_loss: 8439779840.0000\n",
      "Epoch 652/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7615718400.0000 - val_loss: 8621177856.0000\n",
      "Epoch 653/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7617181184.0000 - val_loss: 8314834944.0000\n",
      "Epoch 654/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7688484864.0000 - val_loss: 8532510720.0000\n",
      "Epoch 655/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7635078144.0000 - val_loss: 8380395008.0000\n",
      "Epoch 656/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7706047488.0000 - val_loss: 8343477760.0000\n",
      "Epoch 657/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7782832640.0000 - val_loss: 8325227008.0000\n",
      "Epoch 658/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7724424704.0000 - val_loss: 8616126464.0000\n",
      "Epoch 659/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7749299200.0000 - val_loss: 8418868224.0000\n",
      "Epoch 660/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7707373568.0000 - val_loss: 8435004416.0000\n",
      "Epoch 661/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7595371520.0000 - val_loss: 8335593472.0000\n",
      "Epoch 662/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7674506240.0000 - val_loss: 8352705024.0000\n",
      "Epoch 663/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7812187136.0000 - val_loss: 9343596544.0000\n",
      "Epoch 664/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7935331840.0000 - val_loss: 8369630208.0000\n",
      "Epoch 665/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7580982784.0000 - val_loss: 9408128000.0000\n",
      "Epoch 666/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7836704256.0000 - val_loss: 9194483712.0000\n",
      "Epoch 667/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7656523776.0000 - val_loss: 8536392704.0000\n",
      "Epoch 668/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7659387392.0000 - val_loss: 8508279296.0000\n",
      "Epoch 669/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7617180160.0000 - val_loss: 8339409920.0000\n",
      "Epoch 670/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7696075776.0000 - val_loss: 8411519488.0000\n",
      "Epoch 671/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7746134016.0000 - val_loss: 8599842816.0000\n",
      "Epoch 672/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7823136256.0000 - val_loss: 8383481856.0000\n",
      "Epoch 673/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7766985728.0000 - val_loss: 8314799104.0000\n",
      "Epoch 674/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7831380480.0000 - val_loss: 8468599808.0000\n",
      "Epoch 675/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7707970560.0000 - val_loss: 8439150080.0000\n",
      "Epoch 676/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7702679552.0000 - val_loss: 8584432640.0000\n",
      "Epoch 677/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7749331456.0000 - val_loss: 8895418368.0000\n",
      "Epoch 678/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7682676224.0000 - val_loss: 8285670912.0000\n",
      "Epoch 679/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7606151680.0000 - val_loss: 8593158144.0000\n",
      "Epoch 680/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7825317376.0000 - val_loss: 8646890496.0000\n",
      "Epoch 681/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7829528576.0000 - val_loss: 8361367040.0000\n",
      "Epoch 682/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7606409216.0000 - val_loss: 8358883840.0000\n",
      "Epoch 683/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7687374336.0000 - val_loss: 8351983616.0000\n",
      "Epoch 684/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7773095424.0000 - val_loss: 8366068224.0000\n",
      "Epoch 685/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7724107776.0000 - val_loss: 8378723328.0000\n",
      "Epoch 686/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7680875008.0000 - val_loss: 8331311104.0000\n",
      "Epoch 687/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7691938304.0000 - val_loss: 9607937024.0000\n",
      "Epoch 688/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7735624704.0000 - val_loss: 8408756736.0000\n",
      "Epoch 689/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7887821824.0000 - val_loss: 8642195456.0000\n",
      "Epoch 690/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7721188864.0000 - val_loss: 8910625792.0000\n",
      "Epoch 691/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7588283904.0000 - val_loss: 8305205248.0000\n",
      "Epoch 692/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7609524736.0000 - val_loss: 8694643712.0000\n",
      "Epoch 693/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7642685952.0000 - val_loss: 8580642816.0000\n",
      "Epoch 694/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7613693440.0000 - val_loss: 8362583040.0000\n",
      "Epoch 695/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7680609792.0000 - val_loss: 8477054464.0000\n",
      "Epoch 696/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7671225856.0000 - val_loss: 8343664640.0000\n",
      "Epoch 697/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7826956288.0000 - val_loss: 9147898880.0000\n",
      "Epoch 698/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7804578816.0000 - val_loss: 8350667776.0000\n",
      "Epoch 699/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7817092608.0000 - val_loss: 8623585280.0000\n",
      "Epoch 700/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7710311936.0000 - val_loss: 8274576896.0000\n",
      "Epoch 701/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7727099904.0000 - val_loss: 8363169792.0000\n",
      "Epoch 702/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7940560896.0000 - val_loss: 8285069312.0000\n",
      "Epoch 703/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7689971200.0000 - val_loss: 9704572928.0000\n",
      "Epoch 704/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7595813376.0000 - val_loss: 8874395648.0000\n",
      "Epoch 705/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7544795136.0000 - val_loss: 9714680832.0000\n",
      "Epoch 706/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7840253952.0000 - val_loss: 8360474112.0000\n",
      "Epoch 707/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7740993536.0000 - val_loss: 9260116992.0000\n",
      "Epoch 708/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7693227520.0000 - val_loss: 8423065600.0000\n",
      "Epoch 709/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7615059968.0000 - val_loss: 8905900032.0000\n",
      "Epoch 710/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7526737920.0000 - val_loss: 10058174464.0000\n",
      "Epoch 711/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7838395904.0000 - val_loss: 8821364736.0000\n",
      "Epoch 712/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7667998720.0000 - val_loss: 9697520640.0000\n",
      "Epoch 713/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7703131648.0000 - val_loss: 8375837184.0000\n",
      "Epoch 714/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7636547584.0000 - val_loss: 8530926080.0000\n",
      "Epoch 715/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7668852224.0000 - val_loss: 8275389440.0000\n",
      "Epoch 716/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7726397952.0000 - val_loss: 8853749760.0000\n",
      "Epoch 717/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7746716672.0000 - val_loss: 9386411008.0000\n",
      "Epoch 718/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7664880640.0000 - val_loss: 8673445888.0000\n",
      "Epoch 719/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7714425856.0000 - val_loss: 8311417344.0000\n",
      "Epoch 720/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7712265216.0000 - val_loss: 8378347008.0000\n",
      "Epoch 721/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7577467904.0000 - val_loss: 8297933824.0000\n",
      "Epoch 722/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7669628928.0000 - val_loss: 8344923136.0000\n",
      "Epoch 723/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7577520128.0000 - val_loss: 9001516032.0000\n",
      "Epoch 724/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7728890880.0000 - val_loss: 8346969600.0000\n",
      "Epoch 725/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7574964224.0000 - val_loss: 8505693696.0000\n",
      "Epoch 726/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7755214848.0000 - val_loss: 9060787200.0000\n",
      "Epoch 727/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7858898432.0000 - val_loss: 8626532352.0000\n",
      "Epoch 728/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7665515008.0000 - val_loss: 8540381184.0000\n",
      "Epoch 729/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7682928128.0000 - val_loss: 8807875584.0000\n",
      "Epoch 730/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7689124352.0000 - val_loss: 8963251200.0000\n",
      "Epoch 731/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7801772544.0000 - val_loss: 8277846528.0000\n",
      "Epoch 732/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7580114432.0000 - val_loss: 8284547072.0000\n",
      "Epoch 733/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7482119680.0000 - val_loss: 8400751104.0000\n",
      "Epoch 734/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7578074112.0000 - val_loss: 8356041216.0000\n",
      "Epoch 735/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7724361216.0000 - val_loss: 8571500544.0000\n",
      "Epoch 736/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7861446656.0000 - val_loss: 8417866752.0000\n",
      "Epoch 737/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7759724544.0000 - val_loss: 8273892864.0000\n",
      "Epoch 738/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7629646848.0000 - val_loss: 8274430464.0000\n",
      "Epoch 739/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7832446976.0000 - val_loss: 8796246016.0000\n",
      "Epoch 740/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7635287040.0000 - val_loss: 8500102656.0000\n",
      "Epoch 741/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7725201920.0000 - val_loss: 8540499456.0000\n",
      "Epoch 742/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7554450432.0000 - val_loss: 8262556160.0000\n",
      "Epoch 743/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7677297152.0000 - val_loss: 8243348480.0000\n",
      "Epoch 744/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7570567168.0000 - val_loss: 8364711936.0000\n",
      "Epoch 745/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7647094784.0000 - val_loss: 9234812928.0000\n",
      "Epoch 746/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7574813696.0000 - val_loss: 8314900480.0000\n",
      "Epoch 747/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7533499904.0000 - val_loss: 8836149248.0000\n",
      "Epoch 748/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7584587776.0000 - val_loss: 9075518464.0000\n",
      "Epoch 749/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7630240256.0000 - val_loss: 8438026240.0000\n",
      "Epoch 750/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7760740352.0000 - val_loss: 8694507520.0000\n",
      "Epoch 751/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7735465984.0000 - val_loss: 8813845504.0000\n",
      "Epoch 752/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7548089344.0000 - val_loss: 8318300672.0000\n",
      "Epoch 753/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7483231744.0000 - val_loss: 8307609088.0000\n",
      "Epoch 754/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7642492928.0000 - val_loss: 8303682048.0000\n",
      "Epoch 755/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7496343040.0000 - val_loss: 8267893760.0000\n",
      "Epoch 756/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7561584128.0000 - val_loss: 9030499328.0000\n",
      "Epoch 757/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7616259072.0000 - val_loss: 8270802944.0000\n",
      "Epoch 758/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8036509184.0000 - val_loss: 8719180800.0000\n",
      "Epoch 759/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7516107264.0000 - val_loss: 8330594816.0000\n",
      "Epoch 760/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7594677760.0000 - val_loss: 8341918720.0000\n",
      "Epoch 761/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7696545280.0000 - val_loss: 8332646400.0000\n",
      "Epoch 762/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 8028419072.0000 - val_loss: 8682460160.0000\n",
      "Epoch 763/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7555941888.0000 - val_loss: 8578631680.0000\n",
      "Epoch 764/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7619925504.0000 - val_loss: 8321186816.0000\n",
      "Epoch 765/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7530475520.0000 - val_loss: 8505170432.0000\n",
      "Epoch 766/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7472023552.0000 - val_loss: 8340708352.0000\n",
      "Epoch 767/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7529675264.0000 - val_loss: 8283367936.0000\n",
      "Epoch 768/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7571850752.0000 - val_loss: 8207334400.0000\n",
      "Epoch 769/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7662206976.0000 - val_loss: 8263938560.0000\n",
      "Epoch 770/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7577072640.0000 - val_loss: 9072790528.0000\n",
      "Epoch 771/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7550801408.0000 - val_loss: 8368524288.0000\n",
      "Epoch 772/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7460563968.0000 - val_loss: 8403941888.0000\n",
      "Epoch 773/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7739595264.0000 - val_loss: 8306928128.0000\n",
      "Epoch 774/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7672292864.0000 - val_loss: 8373245952.0000\n",
      "Epoch 775/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7646664192.0000 - val_loss: 8248243200.0000\n",
      "Epoch 776/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7598419456.0000 - val_loss: 8338714624.0000\n",
      "Epoch 777/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7592760320.0000 - val_loss: 10173384704.0000\n",
      "Epoch 778/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7740362752.0000 - val_loss: 9744107520.0000\n",
      "Epoch 779/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7613980160.0000 - val_loss: 8429093888.0000\n",
      "Epoch 780/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7770227200.0000 - val_loss: 8416465920.0000\n",
      "Epoch 781/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7639381504.0000 - val_loss: 8444236800.0000\n",
      "Epoch 782/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7559123456.0000 - val_loss: 8435090432.0000\n",
      "Epoch 783/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7713082368.0000 - val_loss: 8412476416.0000\n",
      "Epoch 784/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7554365440.0000 - val_loss: 8867046400.0000\n",
      "Epoch 785/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7544817152.0000 - val_loss: 8936482816.0000\n",
      "Epoch 786/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7642725888.0000 - val_loss: 8359142912.0000\n",
      "Epoch 787/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7529673216.0000 - val_loss: 8555278336.0000\n",
      "Epoch 788/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7496210944.0000 - val_loss: 8556060672.0000\n",
      "Epoch 789/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7757931520.0000 - val_loss: 8633864192.0000\n",
      "Epoch 790/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7748044288.0000 - val_loss: 8250407936.0000\n",
      "Epoch 791/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7667648512.0000 - val_loss: 8439027200.0000\n",
      "Epoch 792/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7502813696.0000 - val_loss: 8219651584.0000\n",
      "Epoch 793/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7613985280.0000 - val_loss: 8391757312.0000\n",
      "Epoch 794/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7646021120.0000 - val_loss: 8309883392.0000\n",
      "Epoch 795/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7497225728.0000 - val_loss: 8779643904.0000\n",
      "Epoch 796/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7603762176.0000 - val_loss: 8467090432.0000\n",
      "Epoch 797/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7724183040.0000 - val_loss: 8196661760.0000\n",
      "Epoch 798/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7582874624.0000 - val_loss: 8352192512.0000\n",
      "Epoch 799/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7533726208.0000 - val_loss: 8784128000.0000\n",
      "Epoch 800/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7585367552.0000 - val_loss: 8206872576.0000\n",
      "Epoch 801/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7612546048.0000 - val_loss: 8198036480.0000\n",
      "Epoch 802/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7834516480.0000 - val_loss: 8299611648.0000\n",
      "Epoch 803/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7491514880.0000 - val_loss: 8296002048.0000\n",
      "Epoch 804/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7571063296.0000 - val_loss: 8256445440.0000\n",
      "Epoch 805/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7566599168.0000 - val_loss: 10330043392.0000\n",
      "Epoch 806/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7571091968.0000 - val_loss: 8296441344.0000\n",
      "Epoch 807/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7532536832.0000 - val_loss: 8642356224.0000\n",
      "Epoch 808/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7689164288.0000 - val_loss: 8602216448.0000\n",
      "Epoch 809/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7570897920.0000 - val_loss: 8349281792.0000\n",
      "Epoch 810/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7674437632.0000 - val_loss: 8330540544.0000\n",
      "Epoch 811/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7463569408.0000 - val_loss: 8386455552.0000\n",
      "Epoch 812/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7615070720.0000 - val_loss: 8337991168.0000\n",
      "Epoch 813/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7507238400.0000 - val_loss: 8197921280.0000\n",
      "Epoch 814/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7526636032.0000 - val_loss: 8218799616.0000\n",
      "Epoch 815/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7782754304.0000 - val_loss: 8289384448.0000\n",
      "Epoch 816/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7685153280.0000 - val_loss: 8839741440.0000\n",
      "Epoch 817/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7593054208.0000 - val_loss: 8323893760.0000\n",
      "Epoch 818/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7617092096.0000 - val_loss: 8835449856.0000\n",
      "Epoch 819/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7637075968.0000 - val_loss: 8231603712.0000\n",
      "Epoch 820/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7511560192.0000 - val_loss: 8296666624.0000\n",
      "Epoch 821/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7707820032.0000 - val_loss: 8680220672.0000\n",
      "Epoch 822/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7855181824.0000 - val_loss: 8313408512.0000\n",
      "Epoch 823/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7473922048.0000 - val_loss: 9102339072.0000\n",
      "Epoch 824/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7520792064.0000 - val_loss: 8352492032.0000\n",
      "Epoch 825/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7602717184.0000 - val_loss: 8263787520.0000\n",
      "Epoch 826/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7554558976.0000 - val_loss: 8792072192.0000\n",
      "Epoch 827/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7481578496.0000 - val_loss: 8449844736.0000\n",
      "Epoch 828/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7745908224.0000 - val_loss: 8313662976.0000\n",
      "Epoch 829/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7549629952.0000 - val_loss: 8569540608.0000\n",
      "Epoch 830/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7660539904.0000 - val_loss: 8316464640.0000\n",
      "Epoch 831/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7580352000.0000 - val_loss: 8959736832.0000\n",
      "Epoch 832/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7502798336.0000 - val_loss: 9432668160.0000\n",
      "Epoch 833/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7643327488.0000 - val_loss: 8340661248.0000\n",
      "Epoch 834/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7756033024.0000 - val_loss: 8291827200.0000\n",
      "Epoch 835/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7510197248.0000 - val_loss: 8894834688.0000\n",
      "Epoch 836/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7511022592.0000 - val_loss: 8307068416.0000\n",
      "Epoch 837/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7609737216.0000 - val_loss: 8987512832.0000\n",
      "Epoch 838/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7541056512.0000 - val_loss: 8305625088.0000\n",
      "Epoch 839/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7796462592.0000 - val_loss: 8294858752.0000\n",
      "Epoch 840/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7494272512.0000 - val_loss: 8265851392.0000\n",
      "Epoch 841/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7614866944.0000 - val_loss: 9662080000.0000\n",
      "Epoch 842/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7558692864.0000 - val_loss: 8606341120.0000\n",
      "Epoch 843/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7591208960.0000 - val_loss: 8781776896.0000\n",
      "Epoch 844/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7658219008.0000 - val_loss: 8563346944.0000\n",
      "Epoch 845/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7502734848.0000 - val_loss: 8513510912.0000\n",
      "Epoch 846/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7516339200.0000 - val_loss: 8216232960.0000\n",
      "Epoch 847/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7551435776.0000 - val_loss: 8233562112.0000\n",
      "Epoch 848/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7474233344.0000 - val_loss: 8361220608.0000\n",
      "Epoch 849/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7646014976.0000 - val_loss: 8471053312.0000\n",
      "Epoch 850/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7610415616.0000 - val_loss: 8267145728.0000\n",
      "Epoch 851/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7764485120.0000 - val_loss: 8446195200.0000\n",
      "Epoch 852/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7462269440.0000 - val_loss: 8554002944.0000\n",
      "Epoch 853/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7674510336.0000 - val_loss: 8521904128.0000\n",
      "Epoch 854/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7840172544.0000 - val_loss: 9867609088.0000\n",
      "Epoch 855/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7628120064.0000 - val_loss: 8351841280.0000\n",
      "Epoch 856/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7497184256.0000 - val_loss: 8555996160.0000\n",
      "Epoch 857/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7550111232.0000 - val_loss: 8768316416.0000\n",
      "Epoch 858/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7578448384.0000 - val_loss: 8240143872.0000\n",
      "Epoch 859/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7808001024.0000 - val_loss: 8983720960.0000\n",
      "Epoch 860/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7489871872.0000 - val_loss: 8489166336.0000\n",
      "Epoch 861/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7574581760.0000 - val_loss: 8246681088.0000\n",
      "Epoch 862/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7433123840.0000 - val_loss: 8740598784.0000\n",
      "Epoch 863/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7551735808.0000 - val_loss: 8275390464.0000\n",
      "Epoch 864/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7514699776.0000 - val_loss: 8246699520.0000\n",
      "Epoch 865/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7473437184.0000 - val_loss: 8345217536.0000\n",
      "Epoch 866/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7457179648.0000 - val_loss: 9063697408.0000\n",
      "Epoch 867/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7831372288.0000 - val_loss: 8375633408.0000\n",
      "Epoch 868/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7524725248.0000 - val_loss: 8429500928.0000\n",
      "Epoch 869/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7559885824.0000 - val_loss: 8243963392.0000\n",
      "Epoch 870/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7501429760.0000 - val_loss: 8488998400.0000\n",
      "Epoch 871/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7553860608.0000 - val_loss: 8185188864.0000\n",
      "Epoch 872/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7549638144.0000 - val_loss: 8182158336.0000\n",
      "Epoch 873/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7642057728.0000 - val_loss: 8203079168.0000\n",
      "Epoch 874/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7474707968.0000 - val_loss: 8188893184.0000\n",
      "Epoch 875/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7492954624.0000 - val_loss: 8399427072.0000\n",
      "Epoch 876/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7533431296.0000 - val_loss: 8331820544.0000\n",
      "Epoch 877/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7454817280.0000 - val_loss: 8577699840.0000\n",
      "Epoch 878/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7477287936.0000 - val_loss: 8206162944.0000\n",
      "Epoch 879/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7474690048.0000 - val_loss: 8383317504.0000\n",
      "Epoch 880/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7653580800.0000 - val_loss: 8443985408.0000\n",
      "Epoch 881/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7446172160.0000 - val_loss: 8681431040.0000\n",
      "Epoch 882/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7538717184.0000 - val_loss: 8429600768.0000\n",
      "Epoch 883/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7674852864.0000 - val_loss: 8721612800.0000\n",
      "Epoch 884/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7485006848.0000 - val_loss: 8338821120.0000\n",
      "Epoch 885/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7524792320.0000 - val_loss: 8181005312.0000\n",
      "Epoch 886/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7437453312.0000 - val_loss: 8202704384.0000\n",
      "Epoch 887/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7528080896.0000 - val_loss: 8354831872.0000\n",
      "Epoch 888/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7478359040.0000 - val_loss: 8564964864.0000\n",
      "Epoch 889/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7517511680.0000 - val_loss: 8185643520.0000\n",
      "Epoch 890/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7702934016.0000 - val_loss: 8356707328.0000\n",
      "Epoch 891/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7588587008.0000 - val_loss: 8196823040.0000\n",
      "Epoch 892/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7530890240.0000 - val_loss: 8895637504.0000\n",
      "Epoch 893/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7574429696.0000 - val_loss: 8539411968.0000\n",
      "Epoch 894/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7546541568.0000 - val_loss: 8620803072.0000\n",
      "Epoch 895/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7486235648.0000 - val_loss: 8824311808.0000\n",
      "Epoch 896/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7588625408.0000 - val_loss: 8189299712.0000\n",
      "Epoch 897/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7539815424.0000 - val_loss: 8193868288.0000\n",
      "Epoch 898/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7422362112.0000 - val_loss: 8321403392.0000\n",
      "Epoch 899/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7544151040.0000 - val_loss: 8326614528.0000\n",
      "Epoch 900/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7609829888.0000 - val_loss: 8303633920.0000\n",
      "Epoch 901/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7676115968.0000 - val_loss: 8155186176.0000\n",
      "Epoch 902/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7504926720.0000 - val_loss: 8432599040.0000\n",
      "Epoch 903/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7594596864.0000 - val_loss: 8278631936.0000\n",
      "Epoch 904/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7523561984.0000 - val_loss: 8401727488.0000\n",
      "Epoch 905/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7562858496.0000 - val_loss: 8145285120.0000\n",
      "Epoch 906/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7415704576.0000 - val_loss: 8355547648.0000\n",
      "Epoch 907/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7490170368.0000 - val_loss: 8994080768.0000\n",
      "Epoch 908/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7425326080.0000 - val_loss: 8314617344.0000\n",
      "Epoch 909/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7406308352.0000 - val_loss: 8389451264.0000\n",
      "Epoch 910/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7450417664.0000 - val_loss: 8164954112.0000\n",
      "Epoch 911/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7478268928.0000 - val_loss: 9062065152.0000\n",
      "Epoch 912/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7696649728.0000 - val_loss: 8197623296.0000\n",
      "Epoch 913/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7615366656.0000 - val_loss: 8202991616.0000\n",
      "Epoch 914/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7978396672.0000 - val_loss: 8709405696.0000\n",
      "Epoch 915/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7338353152.0000 - val_loss: 8350956544.0000\n",
      "Epoch 916/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7449263104.0000 - val_loss: 8140750336.0000\n",
      "Epoch 917/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7516606464.0000 - val_loss: 8222436864.0000\n",
      "Epoch 918/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7470191104.0000 - val_loss: 8814914560.0000\n",
      "Epoch 919/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7383498240.0000 - val_loss: 8579217408.0000\n",
      "Epoch 920/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7485452800.0000 - val_loss: 8660216832.0000\n",
      "Epoch 921/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7583544832.0000 - val_loss: 8636109824.0000\n",
      "Epoch 922/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7510412288.0000 - val_loss: 9512454144.0000\n",
      "Epoch 923/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7568468992.0000 - val_loss: 8506542080.0000\n",
      "Epoch 924/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7532086784.0000 - val_loss: 8262164992.0000\n",
      "Epoch 925/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7491272704.0000 - val_loss: 8251054592.0000\n",
      "Epoch 926/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7515781632.0000 - val_loss: 8327745536.0000\n",
      "Epoch 927/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7578716672.0000 - val_loss: 9476556800.0000\n",
      "Epoch 928/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7462142464.0000 - val_loss: 8343852544.0000\n",
      "Epoch 929/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7644043264.0000 - val_loss: 8232379904.0000\n",
      "Epoch 930/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7438194688.0000 - val_loss: 8679228416.0000\n",
      "Epoch 931/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7430034432.0000 - val_loss: 8788560896.0000\n",
      "Epoch 932/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7655924736.0000 - val_loss: 8186619904.0000\n",
      "Epoch 933/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7507453440.0000 - val_loss: 8143631360.0000\n",
      "Epoch 934/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7399994368.0000 - val_loss: 8165156352.0000\n",
      "Epoch 935/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7597920256.0000 - val_loss: 8209452032.0000\n",
      "Epoch 936/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7489220096.0000 - val_loss: 8359742464.0000\n",
      "Epoch 937/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7588102144.0000 - val_loss: 8328123392.0000\n",
      "Epoch 938/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7484105216.0000 - val_loss: 8187428352.0000\n",
      "Epoch 939/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7445716480.0000 - val_loss: 8175393280.0000\n",
      "Epoch 940/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7548562944.0000 - val_loss: 9089225728.0000\n",
      "Epoch 941/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7470427136.0000 - val_loss: 8246384640.0000\n",
      "Epoch 942/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7581559296.0000 - val_loss: 9796206592.0000\n",
      "Epoch 943/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7532439552.0000 - val_loss: 8377112064.0000\n",
      "Epoch 944/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7609128960.0000 - val_loss: 8462231552.0000\n",
      "Epoch 945/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7641297920.0000 - val_loss: 8416653312.0000\n",
      "Epoch 946/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7448115712.0000 - val_loss: 8420748800.0000\n",
      "Epoch 947/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7492233728.0000 - val_loss: 8609651712.0000\n",
      "Epoch 948/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7548106240.0000 - val_loss: 8139334656.0000\n",
      "Epoch 949/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7469768704.0000 - val_loss: 8632728576.0000\n",
      "Epoch 950/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7363130368.0000 - val_loss: 8381518848.0000\n",
      "Epoch 951/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7590220288.0000 - val_loss: 8350199296.0000\n",
      "Epoch 952/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7431937536.0000 - val_loss: 8283817472.0000\n",
      "Epoch 953/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7412015616.0000 - val_loss: 8170914816.0000\n",
      "Epoch 954/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7517623808.0000 - val_loss: 8197622784.0000\n",
      "Epoch 955/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7571857920.0000 - val_loss: 8591179776.0000\n",
      "Epoch 956/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7754254336.0000 - val_loss: 8277645312.0000\n",
      "Epoch 957/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7647375872.0000 - val_loss: 8774729728.0000\n",
      "Epoch 958/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7404389888.0000 - val_loss: 8338356224.0000\n",
      "Epoch 959/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7650234368.0000 - val_loss: 8227949568.0000\n",
      "Epoch 960/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7357592064.0000 - val_loss: 8188884480.0000\n",
      "Epoch 961/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7415096320.0000 - val_loss: 8484187648.0000\n",
      "Epoch 962/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7284844032.0000 - val_loss: 8189004288.0000\n",
      "Epoch 963/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7537111552.0000 - val_loss: 8121445376.0000\n",
      "Epoch 964/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7474060800.0000 - val_loss: 8955969536.0000\n",
      "Epoch 965/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7604227072.0000 - val_loss: 8440480768.0000\n",
      "Epoch 966/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7530790912.0000 - val_loss: 8224702976.0000\n",
      "Epoch 967/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7474931712.0000 - val_loss: 8117678592.0000\n",
      "Epoch 968/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7428372992.0000 - val_loss: 8308298240.0000\n",
      "Epoch 969/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7349771264.0000 - val_loss: 8286682112.0000\n",
      "Epoch 970/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7475967488.0000 - val_loss: 8224423936.0000\n",
      "Epoch 971/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7587413504.0000 - val_loss: 8291238400.0000\n",
      "Epoch 972/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7419712512.0000 - val_loss: 8179868160.0000\n",
      "Epoch 973/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7478504960.0000 - val_loss: 8151276032.0000\n",
      "Epoch 974/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7482316800.0000 - val_loss: 8161131008.0000\n",
      "Epoch 975/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7367897600.0000 - val_loss: 8408416768.0000\n",
      "Epoch 976/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7545177600.0000 - val_loss: 8277575680.0000\n",
      "Epoch 977/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7400642048.0000 - val_loss: 8178498560.0000\n",
      "Epoch 978/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7569193984.0000 - val_loss: 8115852800.0000\n",
      "Epoch 979/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7561437696.0000 - val_loss: 8368412672.0000\n",
      "Epoch 980/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7513792000.0000 - val_loss: 8419011584.0000\n",
      "Epoch 981/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7519387136.0000 - val_loss: 8350612480.0000\n",
      "Epoch 982/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7516854272.0000 - val_loss: 8155707392.0000\n",
      "Epoch 983/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7342984192.0000 - val_loss: 8372963328.0000\n",
      "Epoch 984/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7471219712.0000 - val_loss: 8210940416.0000\n",
      "Epoch 985/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7520581120.0000 - val_loss: 9179289600.0000\n",
      "Epoch 986/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7448885760.0000 - val_loss: 8178981376.0000\n",
      "Epoch 987/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7515305472.0000 - val_loss: 8176402432.0000\n",
      "Epoch 988/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7618589696.0000 - val_loss: 8590713856.0000\n",
      "Epoch 989/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7500318720.0000 - val_loss: 8421049344.0000\n",
      "Epoch 990/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7382672896.0000 - val_loss: 8516827648.0000\n",
      "Epoch 991/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7379737088.0000 - val_loss: 8265691136.0000\n",
      "Epoch 992/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7479088640.0000 - val_loss: 9106292736.0000\n",
      "Epoch 993/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7447721984.0000 - val_loss: 8174019584.0000\n",
      "Epoch 994/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7451864064.0000 - val_loss: 8220322304.0000\n",
      "Epoch 995/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7532770304.0000 - val_loss: 8505080832.0000\n",
      "Epoch 996/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7462877184.0000 - val_loss: 8209176064.0000\n",
      "Epoch 997/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7481914880.0000 - val_loss: 8194165248.0000\n",
      "Epoch 998/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7400114688.0000 - val_loss: 8197228032.0000\n",
      "Epoch 999/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7437148672.0000 - val_loss: 8210168320.0000\n",
      "Epoch 1000/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7368060416.0000 - val_loss: 8385394688.0000\n",
      "Epoch 1001/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7400218624.0000 - val_loss: 8249809408.0000\n",
      "Epoch 1002/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7569010176.0000 - val_loss: 8196477440.0000\n",
      "Epoch 1003/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7354040832.0000 - val_loss: 8265362944.0000\n",
      "Epoch 1004/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7444642816.0000 - val_loss: 8133043200.0000\n",
      "Epoch 1005/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7448372224.0000 - val_loss: 8338273792.0000\n",
      "Epoch 1006/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7388406272.0000 - val_loss: 8418727424.0000\n",
      "Epoch 1007/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7373332480.0000 - val_loss: 8390852608.0000\n",
      "Epoch 1008/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7389337088.0000 - val_loss: 8592754688.0000\n",
      "Epoch 1009/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7722871808.0000 - val_loss: 8206148608.0000\n",
      "Epoch 1010/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7559696384.0000 - val_loss: 8346855936.0000\n",
      "Epoch 1011/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7459127808.0000 - val_loss: 8287990272.0000\n",
      "Epoch 1012/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7398568960.0000 - val_loss: 8129163264.0000\n",
      "Epoch 1013/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7501606912.0000 - val_loss: 8707700736.0000\n",
      "Epoch 1014/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7365949440.0000 - val_loss: 8521946112.0000\n",
      "Epoch 1015/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7476778496.0000 - val_loss: 8340893696.0000\n",
      "Epoch 1016/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7506648576.0000 - val_loss: 8713891840.0000\n",
      "Epoch 1017/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7524178432.0000 - val_loss: 8191800320.0000\n",
      "Epoch 1018/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7489946624.0000 - val_loss: 8125267968.0000\n",
      "Epoch 1019/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7406451712.0000 - val_loss: 8106945024.0000\n",
      "Epoch 1020/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7356664832.0000 - val_loss: 8289039872.0000\n",
      "Epoch 1021/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7460140544.0000 - val_loss: 8348534272.0000\n",
      "Epoch 1022/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7429071360.0000 - val_loss: 8115834880.0000\n",
      "Epoch 1023/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7467418624.0000 - val_loss: 8128036352.0000\n",
      "Epoch 1024/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7533087744.0000 - val_loss: 8398505472.0000\n",
      "Epoch 1025/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7298946560.0000 - val_loss: 8362525696.0000\n",
      "Epoch 1026/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7348659712.0000 - val_loss: 8155367936.0000\n",
      "Epoch 1027/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7441647104.0000 - val_loss: 8301058560.0000\n",
      "Epoch 1028/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7767589888.0000 - val_loss: 8179733504.0000\n",
      "Epoch 1029/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7315854336.0000 - val_loss: 9314463744.0000\n",
      "Epoch 1030/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7423819264.0000 - val_loss: 8375955456.0000\n",
      "Epoch 1031/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7337942016.0000 - val_loss: 8525998592.0000\n",
      "Epoch 1032/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7440951296.0000 - val_loss: 9321950208.0000\n",
      "Epoch 1033/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7441287168.0000 - val_loss: 8115607552.0000\n",
      "Epoch 1034/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7595113472.0000 - val_loss: 8322095104.0000\n",
      "Epoch 1035/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7581693440.0000 - val_loss: 8182526464.0000\n",
      "Epoch 1036/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7330643968.0000 - val_loss: 8386381312.0000\n",
      "Epoch 1037/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7375456768.0000 - val_loss: 8174525440.0000\n",
      "Epoch 1038/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7277648896.0000 - val_loss: 8263886848.0000\n",
      "Epoch 1039/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7535976960.0000 - val_loss: 8212735488.0000\n",
      "Epoch 1040/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7483318784.0000 - val_loss: 9531890688.0000\n",
      "Epoch 1041/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7405412864.0000 - val_loss: 8144873472.0000\n",
      "Epoch 1042/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7331788288.0000 - val_loss: 8274105344.0000\n",
      "Epoch 1043/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7466115072.0000 - val_loss: 8149233664.0000\n",
      "Epoch 1044/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7484435456.0000 - val_loss: 9180444672.0000\n",
      "Epoch 1045/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7338634752.0000 - val_loss: 8132869632.0000\n",
      "Epoch 1046/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7276812288.0000 - val_loss: 8179856384.0000\n",
      "Epoch 1047/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7365305856.0000 - val_loss: 8206420992.0000\n",
      "Epoch 1048/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7417474048.0000 - val_loss: 8255677440.0000\n",
      "Epoch 1049/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7424193024.0000 - val_loss: 8479186432.0000\n",
      "Epoch 1050/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7401695744.0000 - val_loss: 9248814080.0000\n",
      "Epoch 1051/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7396627456.0000 - val_loss: 8125558272.0000\n",
      "Epoch 1052/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7352980992.0000 - val_loss: 8158075904.0000\n",
      "Epoch 1053/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7475215360.0000 - val_loss: 8252730368.0000\n",
      "Epoch 1054/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7322854400.0000 - val_loss: 9200643072.0000\n",
      "Epoch 1055/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7453955584.0000 - val_loss: 8603696128.0000\n",
      "Epoch 1056/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7445352448.0000 - val_loss: 8111806976.0000\n",
      "Epoch 1057/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7394679808.0000 - val_loss: 8907877376.0000\n",
      "Epoch 1058/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7496615424.0000 - val_loss: 8201023488.0000\n",
      "Epoch 1059/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7428700672.0000 - val_loss: 8237749248.0000\n",
      "Epoch 1060/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7518282752.0000 - val_loss: 8127638528.0000\n",
      "Epoch 1061/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7433030144.0000 - val_loss: 9315296256.0000\n",
      "Epoch 1062/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7783242240.0000 - val_loss: 8763630592.0000\n",
      "Epoch 1063/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7367223808.0000 - val_loss: 8145043968.0000\n",
      "Epoch 1064/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7565746688.0000 - val_loss: 8331999232.0000\n",
      "Epoch 1065/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7347996160.0000 - val_loss: 8688024576.0000\n",
      "Epoch 1066/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7704736768.0000 - val_loss: 8193251328.0000\n",
      "Epoch 1067/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7566195200.0000 - val_loss: 8165806592.0000\n",
      "Epoch 1068/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7461211136.0000 - val_loss: 8283683328.0000\n",
      "Epoch 1069/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7342778368.0000 - val_loss: 8404993024.0000\n",
      "Epoch 1070/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7379952640.0000 - val_loss: 8145885696.0000\n",
      "Epoch 1071/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7385676800.0000 - val_loss: 8327644160.0000\n",
      "Epoch 1072/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7288063488.0000 - val_loss: 8225817088.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1073/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7498353664.0000 - val_loss: 8187207680.0000\n",
      "Epoch 1074/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7336163328.0000 - val_loss: 8271869440.0000\n",
      "Epoch 1075/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7296956416.0000 - val_loss: 8140907008.0000\n",
      "Epoch 1076/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7603035648.0000 - val_loss: 8624224256.0000\n",
      "Epoch 1077/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7449873920.0000 - val_loss: 8293490688.0000\n",
      "Epoch 1078/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7370668544.0000 - val_loss: 8407823872.0000\n",
      "Epoch 1079/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7342270464.0000 - val_loss: 8150498304.0000\n",
      "Epoch 1080/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7244685824.0000 - val_loss: 8202907648.0000\n",
      "Epoch 1081/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7314317312.0000 - val_loss: 8625038336.0000\n",
      "Epoch 1082/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7503092736.0000 - val_loss: 8273828352.0000\n",
      "Epoch 1083/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7329156608.0000 - val_loss: 8473902080.0000\n",
      "Epoch 1084/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7584887296.0000 - val_loss: 9394884608.0000\n",
      "Epoch 1085/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7582788096.0000 - val_loss: 8199202816.0000\n",
      "Epoch 1086/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7391225856.0000 - val_loss: 8144416768.0000\n",
      "Epoch 1087/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7308229632.0000 - val_loss: 8125064704.0000\n",
      "Epoch 1088/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7281942016.0000 - val_loss: 8107016192.0000\n",
      "Epoch 1089/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7437622784.0000 - val_loss: 8149465088.0000\n",
      "Epoch 1090/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7347309568.0000 - val_loss: 8133869056.0000\n",
      "Epoch 1091/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7368678912.0000 - val_loss: 8183890944.0000\n",
      "Epoch 1092/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7493112320.0000 - val_loss: 9024933888.0000\n",
      "Epoch 1093/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7281305088.0000 - val_loss: 8188120576.0000\n",
      "Epoch 1094/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7404975104.0000 - val_loss: 8227746304.0000\n",
      "Epoch 1095/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7591970816.0000 - val_loss: 9738398720.0000\n",
      "Epoch 1096/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7412254208.0000 - val_loss: 8542718976.0000\n",
      "Epoch 1097/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7504099840.0000 - val_loss: 8263700480.0000\n",
      "Epoch 1098/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7294512128.0000 - val_loss: 8137281536.0000\n",
      "Epoch 1099/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7404517376.0000 - val_loss: 8185072640.0000\n",
      "Epoch 1100/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7275271168.0000 - val_loss: 8306240512.0000\n",
      "Epoch 1101/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7365350400.0000 - val_loss: 8341504000.0000\n",
      "Epoch 1102/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7420738560.0000 - val_loss: 8274099712.0000\n",
      "Epoch 1103/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7542657536.0000 - val_loss: 8898029568.0000\n",
      "Epoch 1104/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7314792960.0000 - val_loss: 8202105856.0000\n",
      "Epoch 1105/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7246556160.0000 - val_loss: 8189268480.0000\n",
      "Epoch 1106/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7355066880.0000 - val_loss: 8206807040.0000\n",
      "Epoch 1107/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7287237120.0000 - val_loss: 8516160000.0000\n",
      "Epoch 1108/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7508837888.0000 - val_loss: 8249717760.0000\n",
      "Epoch 1109/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7257600000.0000 - val_loss: 8237479424.0000\n",
      "Epoch 1110/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7524687872.0000 - val_loss: 8608038912.0000\n",
      "Epoch 1111/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7682045952.0000 - val_loss: 8137541632.0000\n",
      "Epoch 1112/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548521984.0000 - val_loss: 8162662912.0000\n",
      "Epoch 1113/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7423219712.0000 - val_loss: 8090919424.0000\n",
      "Epoch 1114/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7238124544.0000 - val_loss: 8357099008.0000\n",
      "Epoch 1115/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7374784512.0000 - val_loss: 8276140032.0000\n",
      "Epoch 1116/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7353562112.0000 - val_loss: 8680135680.0000\n",
      "Epoch 1117/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7353185792.0000 - val_loss: 8143691264.0000\n",
      "Epoch 1118/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7392778240.0000 - val_loss: 8707948544.0000\n",
      "Epoch 1119/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7534465536.0000 - val_loss: 8462508544.0000\n",
      "Epoch 1120/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7563963904.0000 - val_loss: 9102788608.0000\n",
      "Epoch 1121/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7225050624.0000 - val_loss: 9110461440.0000\n",
      "Epoch 1122/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7460712960.0000 - val_loss: 8599740416.0000\n",
      "Epoch 1123/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7588190208.0000 - val_loss: 8282598912.0000\n",
      "Epoch 1124/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7621981696.0000 - val_loss: 8717879296.0000\n",
      "Epoch 1125/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7377526272.0000 - val_loss: 8279121920.0000\n",
      "Epoch 1126/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7220525568.0000 - val_loss: 8381530112.0000\n",
      "Epoch 1127/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7322168320.0000 - val_loss: 8491712000.0000\n",
      "Epoch 1128/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7353049088.0000 - val_loss: 8145282560.0000\n",
      "Epoch 1129/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7304157184.0000 - val_loss: 8595346432.0000\n",
      "Epoch 1130/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7354925568.0000 - val_loss: 8280736256.0000\n",
      "Epoch 1131/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7380342784.0000 - val_loss: 8425316352.0000\n",
      "Epoch 1132/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7266886144.0000 - val_loss: 8116097536.0000\n",
      "Epoch 1133/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7380319744.0000 - val_loss: 8112599040.0000\n",
      "Epoch 1134/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7480096256.0000 - val_loss: 8975405056.0000\n",
      "Epoch 1135/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7255764992.0000 - val_loss: 8178706432.0000\n",
      "Epoch 1136/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7279448064.0000 - val_loss: 8485144064.0000\n",
      "Epoch 1137/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7470108672.0000 - val_loss: 10167385088.0000\n",
      "Epoch 1138/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7351760384.0000 - val_loss: 8314378240.0000\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7490728960.0000 - val_loss: 8207796224.0000\n",
      "Epoch 1140/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7342487552.0000 - val_loss: 8245971456.0000\n",
      "Epoch 1141/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7489175552.0000 - val_loss: 9550710784.0000\n",
      "Epoch 1142/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7435122688.0000 - val_loss: 8220514304.0000\n",
      "Epoch 1143/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7652231168.0000 - val_loss: 8195037184.0000\n",
      "Epoch 1144/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7295303168.0000 - val_loss: 8088498688.0000\n",
      "Epoch 1145/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7194185728.0000 - val_loss: 8206453248.0000\n",
      "Epoch 1146/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7482821632.0000 - val_loss: 8737260544.0000\n",
      "Epoch 1147/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7380304384.0000 - val_loss: 8105563648.0000\n",
      "Epoch 1148/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7355183616.0000 - val_loss: 8913790976.0000\n",
      "Epoch 1149/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7236030976.0000 - val_loss: 8113458688.0000\n",
      "Epoch 1150/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7373318656.0000 - val_loss: 8103938560.0000\n",
      "Epoch 1151/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7252494848.0000 - val_loss: 8143051264.0000\n",
      "Epoch 1152/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7412691968.0000 - val_loss: 9168626688.0000\n",
      "Epoch 1153/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7318405120.0000 - val_loss: 8082566144.0000\n",
      "Epoch 1154/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7567152640.0000 - val_loss: 8134210048.0000\n",
      "Epoch 1155/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7561773056.0000 - val_loss: 8965784576.0000\n",
      "Epoch 1156/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7349840384.0000 - val_loss: 8279876608.0000\n",
      "Epoch 1157/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7393253888.0000 - val_loss: 8974408704.0000\n",
      "Epoch 1158/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7544888320.0000 - val_loss: 8937277440.0000\n",
      "Epoch 1159/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7297405440.0000 - val_loss: 8108170240.0000\n",
      "Epoch 1160/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7405190144.0000 - val_loss: 8657594368.0000\n",
      "Epoch 1161/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7242056192.0000 - val_loss: 8107892224.0000\n",
      "Epoch 1162/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7304239616.0000 - val_loss: 8230796288.0000\n",
      "Epoch 1163/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7344613888.0000 - val_loss: 9077832704.0000\n",
      "Epoch 1164/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7224570880.0000 - val_loss: 8060513280.0000\n",
      "Epoch 1165/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7186883072.0000 - val_loss: 8197641216.0000\n",
      "Epoch 1166/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7239681024.0000 - val_loss: 8242312704.0000\n",
      "Epoch 1167/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7216770560.0000 - val_loss: 8258505728.0000\n",
      "Epoch 1168/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7458729984.0000 - val_loss: 8090437120.0000\n",
      "Epoch 1169/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7342835712.0000 - val_loss: 8058413568.0000\n",
      "Epoch 1170/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7356969472.0000 - val_loss: 8390714880.0000\n",
      "Epoch 1171/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7355981824.0000 - val_loss: 8211618816.0000\n",
      "Epoch 1172/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7429099520.0000 - val_loss: 8198406144.0000\n",
      "Epoch 1173/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7337777664.0000 - val_loss: 8075108864.0000\n",
      "Epoch 1174/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7314162176.0000 - val_loss: 8574986752.0000\n",
      "Epoch 1175/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7337741312.0000 - val_loss: 8621387776.0000\n",
      "Epoch 1176/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7405816832.0000 - val_loss: 9090985984.0000\n",
      "Epoch 1177/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7319345664.0000 - val_loss: 8153136640.0000\n",
      "Epoch 1178/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7397596160.0000 - val_loss: 8359397888.0000\n",
      "Epoch 1179/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7299474432.0000 - val_loss: 8110798848.0000\n",
      "Epoch 1180/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7253060096.0000 - val_loss: 8135622144.0000\n",
      "Epoch 1181/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7381950976.0000 - val_loss: 8088894976.0000\n",
      "Epoch 1182/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7314963456.0000 - val_loss: 8166889984.0000\n",
      "Epoch 1183/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7341534720.0000 - val_loss: 8092755456.0000\n",
      "Epoch 1184/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7249799168.0000 - val_loss: 8300212224.0000\n",
      "Epoch 1185/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7188635648.0000 - val_loss: 8342493184.0000\n",
      "Epoch 1186/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7280997888.0000 - val_loss: 8620889088.0000\n",
      "Epoch 1187/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7315922944.0000 - val_loss: 8461007872.0000\n",
      "Epoch 1188/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7267390976.0000 - val_loss: 8373884928.0000\n",
      "Epoch 1189/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7433780736.0000 - val_loss: 8416191488.0000\n",
      "Epoch 1190/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7218659840.0000 - val_loss: 8190228480.0000\n",
      "Epoch 1191/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7396857344.0000 - val_loss: 8130021888.0000\n",
      "Epoch 1192/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7247620096.0000 - val_loss: 8068887040.0000\n",
      "Epoch 1193/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7372873728.0000 - val_loss: 8415673344.0000\n",
      "Epoch 1194/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7640496640.0000 - val_loss: 8638918656.0000\n",
      "Epoch 1195/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7265063936.0000 - val_loss: 8081610240.0000\n",
      "Epoch 1196/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7392386560.0000 - val_loss: 9402407936.0000\n",
      "Epoch 1197/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7250284544.0000 - val_loss: 8145714688.0000\n",
      "Epoch 1198/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7317585408.0000 - val_loss: 8381557760.0000\n",
      "Epoch 1199/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7283930624.0000 - val_loss: 8161920000.0000\n",
      "Epoch 1200/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7237009920.0000 - val_loss: 8312549888.0000\n",
      "Epoch 1201/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7235821056.0000 - val_loss: 8115206144.0000\n",
      "Epoch 1202/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7231039488.0000 - val_loss: 8103936512.0000\n",
      "Epoch 1203/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7281583104.0000 - val_loss: 8221059584.0000\n",
      "Epoch 1204/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7375188480.0000 - val_loss: 8257161216.0000\n",
      "Epoch 1205/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7273972736.0000 - val_loss: 8152417792.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1206/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7368821760.0000 - val_loss: 8478749184.0000\n",
      "Epoch 1207/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7459243008.0000 - val_loss: 8865755136.0000\n",
      "Epoch 1208/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7532249600.0000 - val_loss: 8550967808.0000\n",
      "Epoch 1209/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7256872448.0000 - val_loss: 8135220224.0000\n",
      "Epoch 1210/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7226840576.0000 - val_loss: 8113560576.0000\n",
      "Epoch 1211/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7229138944.0000 - val_loss: 8080299008.0000\n",
      "Epoch 1212/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7320484864.0000 - val_loss: 8183988736.0000\n",
      "Epoch 1213/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7277257728.0000 - val_loss: 8054443008.0000\n",
      "Epoch 1214/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7409026560.0000 - val_loss: 8100105216.0000\n",
      "Epoch 1215/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7464453120.0000 - val_loss: 8102817792.0000\n",
      "Epoch 1216/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7234372608.0000 - val_loss: 8102340608.0000\n",
      "Epoch 1217/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7289838592.0000 - val_loss: 8473266176.0000\n",
      "Epoch 1218/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7315744768.0000 - val_loss: 8271840768.0000\n",
      "Epoch 1219/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7694163456.0000 - val_loss: 8144302592.0000\n",
      "Epoch 1220/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7290070016.0000 - val_loss: 8257039360.0000\n",
      "Epoch 1221/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7213082112.0000 - val_loss: 8289867264.0000\n",
      "Epoch 1222/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7391788032.0000 - val_loss: 8209689600.0000\n",
      "Epoch 1223/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7244395520.0000 - val_loss: 8647916544.0000\n",
      "Epoch 1224/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7328120320.0000 - val_loss: 8195070464.0000\n",
      "Epoch 1225/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7387337728.0000 - val_loss: 9017234432.0000\n",
      "Epoch 1226/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7539622912.0000 - val_loss: 8149972480.0000\n",
      "Epoch 1227/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7232734208.0000 - val_loss: 8601739264.0000\n",
      "Epoch 1228/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7408522752.0000 - val_loss: 8138916352.0000\n",
      "Epoch 1229/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7251737088.0000 - val_loss: 8407415296.0000\n",
      "Epoch 1230/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7307586560.0000 - val_loss: 8307790848.0000\n",
      "Epoch 1231/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7630594560.0000 - val_loss: 8326850048.0000\n",
      "Epoch 1232/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7230227968.0000 - val_loss: 8041694208.0000\n",
      "Epoch 1233/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7388213248.0000 - val_loss: 8576918528.0000\n",
      "Epoch 1234/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7421997568.0000 - val_loss: 8216106496.0000\n",
      "Epoch 1235/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7254460928.0000 - val_loss: 8222269440.0000\n",
      "Epoch 1236/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7349687808.0000 - val_loss: 8111200768.0000\n",
      "Epoch 1237/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7218045440.0000 - val_loss: 8174817280.0000\n",
      "Epoch 1238/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7154577408.0000 - val_loss: 8175000576.0000\n",
      "Epoch 1239/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7344556544.0000 - val_loss: 8122415104.0000\n",
      "Epoch 1240/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7239688704.0000 - val_loss: 8095891968.0000\n",
      "Epoch 1241/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7280461824.0000 - val_loss: 8441734656.0000\n",
      "Epoch 1242/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7158106624.0000 - val_loss: 8220330496.0000\n",
      "Epoch 1243/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7355270144.0000 - val_loss: 8105833984.0000\n",
      "Epoch 1244/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7272975360.0000 - val_loss: 8195518464.0000\n",
      "Epoch 1245/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7291503616.0000 - val_loss: 8106639360.0000\n",
      "Epoch 1246/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7253998080.0000 - val_loss: 8474331648.0000\n",
      "Epoch 1247/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7317906944.0000 - val_loss: 8136666112.0000\n",
      "Epoch 1248/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7456989184.0000 - val_loss: 8157674496.0000\n",
      "Epoch 1249/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7321139712.0000 - val_loss: 8241100800.0000\n",
      "Epoch 1250/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7308863488.0000 - val_loss: 8260389376.0000\n",
      "Epoch 1251/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7183137792.0000 - val_loss: 8855575552.0000\n",
      "Epoch 1252/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7274586624.0000 - val_loss: 8090470912.0000\n",
      "Epoch 1253/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7291294720.0000 - val_loss: 10000643072.0000\n",
      "Epoch 1254/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7458628096.0000 - val_loss: 8126504960.0000\n",
      "Epoch 1255/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7222074880.0000 - val_loss: 8477661696.0000\n",
      "Epoch 1256/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7598749184.0000 - val_loss: 8150560256.0000\n",
      "Epoch 1257/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7240617472.0000 - val_loss: 8215885824.0000\n",
      "Epoch 1258/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7149534720.0000 - val_loss: 8160037376.0000\n",
      "Epoch 1259/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7270895104.0000 - val_loss: 8661296128.0000\n",
      "Epoch 1260/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7515640832.0000 - val_loss: 8118602752.0000\n",
      "Epoch 1261/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7238748160.0000 - val_loss: 8180476416.0000\n",
      "Epoch 1262/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7165749248.0000 - val_loss: 8315696128.0000\n",
      "Epoch 1263/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7228976128.0000 - val_loss: 8062382080.0000\n",
      "Epoch 1264/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7329791488.0000 - val_loss: 8261122048.0000\n",
      "Epoch 1265/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7491002880.0000 - val_loss: 8360862720.0000\n",
      "Epoch 1266/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7326045184.0000 - val_loss: 8053841920.0000\n",
      "Epoch 1267/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7172796928.0000 - val_loss: 8165939712.0000\n",
      "Epoch 1268/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7305114112.0000 - val_loss: 8193485312.0000\n",
      "Epoch 1269/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7381973504.0000 - val_loss: 9613991936.0000\n",
      "Epoch 1270/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7232349184.0000 - val_loss: 8395015680.0000\n",
      "Epoch 1271/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7269146112.0000 - val_loss: 8251122176.0000\n",
      "Epoch 1272/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7140346368.0000 - val_loss: 8280768512.0000\n",
      "Epoch 1273/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7386293248.0000 - val_loss: 8693015552.0000\n",
      "Epoch 1274/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7345134592.0000 - val_loss: 8125914112.0000\n",
      "Epoch 1275/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7342074368.0000 - val_loss: 8164310016.0000\n",
      "Epoch 1276/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7255350784.0000 - val_loss: 8613030912.0000\n",
      "Epoch 1277/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7441168896.0000 - val_loss: 8090243584.0000\n",
      "Epoch 1278/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7173145088.0000 - val_loss: 8146557952.0000\n",
      "Epoch 1279/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7332203520.0000 - val_loss: 8100275200.0000\n",
      "Epoch 1280/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7254477312.0000 - val_loss: 8887388160.0000\n",
      "Epoch 1281/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7197700096.0000 - val_loss: 8106055168.0000\n",
      "Epoch 1282/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7318140416.0000 - val_loss: 8150434816.0000\n",
      "Epoch 1283/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7271745536.0000 - val_loss: 8363570176.0000\n",
      "Epoch 1284/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7201055744.0000 - val_loss: 8295218688.0000\n",
      "Epoch 1285/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7285971456.0000 - val_loss: 8274529280.0000\n",
      "Epoch 1286/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7284386304.0000 - val_loss: 8792726528.0000\n",
      "Epoch 1287/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7313665024.0000 - val_loss: 8209154560.0000\n",
      "Epoch 1288/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7200965120.0000 - val_loss: 8038574080.0000\n",
      "Epoch 1289/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7555368960.0000 - val_loss: 8618376192.0000\n",
      "Epoch 1290/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7413594624.0000 - val_loss: 8120679424.0000\n",
      "Epoch 1291/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7289061376.0000 - val_loss: 8274800128.0000\n",
      "Epoch 1292/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7231087616.0000 - val_loss: 8400006656.0000\n",
      "Epoch 1293/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7323126272.0000 - val_loss: 8060588032.0000\n",
      "Epoch 1294/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7318310400.0000 - val_loss: 8269964800.0000\n",
      "Epoch 1295/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7240588288.0000 - val_loss: 8083407360.0000\n",
      "Epoch 1296/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7183340032.0000 - val_loss: 8162473472.0000\n",
      "Epoch 1297/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7326155264.0000 - val_loss: 8126495744.0000\n",
      "Epoch 1298/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7186079232.0000 - val_loss: 8129959936.0000\n",
      "Epoch 1299/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7488208384.0000 - val_loss: 9040697344.0000\n",
      "Epoch 1300/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7229626880.0000 - val_loss: 8208157696.0000\n",
      "Epoch 1301/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7215423488.0000 - val_loss: 8074974208.0000\n",
      "Epoch 1302/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7295918592.0000 - val_loss: 8320715264.0000\n",
      "Epoch 1303/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7449062912.0000 - val_loss: 8386375168.0000\n",
      "Epoch 1304/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7281773056.0000 - val_loss: 8316754944.0000\n",
      "Epoch 1305/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7321725952.0000 - val_loss: 8143467520.0000\n",
      "Epoch 1306/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7281200128.0000 - val_loss: 8463739904.0000\n",
      "Epoch 1307/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7406508544.0000 - val_loss: 8053895168.0000\n",
      "Epoch 1308/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7397207552.0000 - val_loss: 8687918080.0000\n",
      "Epoch 1309/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7410524160.0000 - val_loss: 8212045312.0000\n",
      "Epoch 1310/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7166145024.0000 - val_loss: 8088349696.0000\n",
      "Epoch 1311/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7283697152.0000 - val_loss: 8309083136.0000\n",
      "Epoch 1312/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7293932544.0000 - val_loss: 8171334656.0000\n",
      "Epoch 1313/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7287460352.0000 - val_loss: 8172564480.0000\n",
      "Epoch 1314/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7482668032.0000 - val_loss: 8164549120.0000\n",
      "Epoch 1315/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7095977984.0000 - val_loss: 8307037696.0000\n",
      "Epoch 1316/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7255742976.0000 - val_loss: 8249073152.0000\n",
      "Epoch 1317/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7192873984.0000 - val_loss: 8531028480.0000\n",
      "Epoch 1318/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7187407360.0000 - val_loss: 8482895360.0000\n",
      "Epoch 1319/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7141360640.0000 - val_loss: 8067056128.0000\n",
      "Epoch 1320/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7405086208.0000 - val_loss: 8203690496.0000\n",
      "Epoch 1321/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7276023808.0000 - val_loss: 8317171712.0000\n",
      "Epoch 1322/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7345511936.0000 - val_loss: 8119431168.0000\n",
      "Epoch 1323/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7197547520.0000 - val_loss: 8160903168.0000\n",
      "Epoch 1324/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7218371072.0000 - val_loss: 8068537856.0000\n",
      "Epoch 1325/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7224899584.0000 - val_loss: 8078504960.0000\n",
      "Epoch 1326/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7278048256.0000 - val_loss: 8055931392.0000\n",
      "Epoch 1327/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7288766464.0000 - val_loss: 8051854848.0000\n",
      "Epoch 1328/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7235372544.0000 - val_loss: 8163018240.0000\n",
      "Epoch 1329/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179710464.0000 - val_loss: 8450184704.0000\n",
      "Epoch 1330/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7265522688.0000 - val_loss: 8283272192.0000\n",
      "Epoch 1331/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7274627072.0000 - val_loss: 8367703552.0000\n",
      "Epoch 1332/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7118255616.0000 - val_loss: 8190112256.0000\n",
      "Epoch 1333/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7196898304.0000 - val_loss: 8109482496.0000\n",
      "Epoch 1334/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7303333376.0000 - val_loss: 8188770304.0000\n",
      "Epoch 1335/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7297377280.0000 - val_loss: 9050545152.0000\n",
      "Epoch 1336/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7447233536.0000 - val_loss: 8108198400.0000\n",
      "Epoch 1337/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7311939584.0000 - val_loss: 8593089536.0000\n",
      "Epoch 1338/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7769874432.0000 - val_loss: 9679562752.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1339/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7321018880.0000 - val_loss: 8256589312.0000\n",
      "Epoch 1340/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7238501888.0000 - val_loss: 8298900992.0000\n",
      "Epoch 1341/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7247485952.0000 - val_loss: 8159076864.0000\n",
      "Epoch 1342/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7327012352.0000 - val_loss: 8269476352.0000\n",
      "Epoch 1343/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7086433792.0000 - val_loss: 8116239360.0000\n",
      "Epoch 1344/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7285161472.0000 - val_loss: 8009492480.0000\n",
      "Epoch 1345/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7152275456.0000 - val_loss: 8452784640.0000\n",
      "Epoch 1346/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7160695296.0000 - val_loss: 8243931648.0000\n",
      "Epoch 1347/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7326499840.0000 - val_loss: 8257712640.0000\n",
      "Epoch 1348/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7287758848.0000 - val_loss: 8090676736.0000\n",
      "Epoch 1349/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7253553664.0000 - val_loss: 8253658112.0000\n",
      "Epoch 1350/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7243444736.0000 - val_loss: 9018996736.0000\n",
      "Epoch 1351/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7160138240.0000 - val_loss: 8253441536.0000\n",
      "Epoch 1352/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7286288384.0000 - val_loss: 8430733824.0000\n",
      "Epoch 1353/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7178567168.0000 - val_loss: 8047206912.0000\n",
      "Epoch 1354/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7281481216.0000 - val_loss: 8231812096.0000\n",
      "Epoch 1355/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7223448064.0000 - val_loss: 8658893824.0000\n",
      "Epoch 1356/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7477893632.0000 - val_loss: 8394194432.0000\n",
      "Epoch 1357/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7228861440.0000 - val_loss: 9022346240.0000\n",
      "Epoch 1358/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7341987840.0000 - val_loss: 8102144000.0000\n",
      "Epoch 1359/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7252935680.0000 - val_loss: 8475547136.0000\n",
      "Epoch 1360/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7303341056.0000 - val_loss: 8406123520.0000\n",
      "Epoch 1361/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7176286208.0000 - val_loss: 8210215424.0000\n",
      "Epoch 1362/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7265405952.0000 - val_loss: 8140425216.0000\n",
      "Epoch 1363/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7181912064.0000 - val_loss: 8094552576.0000\n",
      "Epoch 1364/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7278342144.0000 - val_loss: 9225636864.0000\n",
      "Epoch 1365/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7457247744.0000 - val_loss: 9857615872.0000\n",
      "Epoch 1366/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7236984832.0000 - val_loss: 8599093248.0000\n",
      "Epoch 1367/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7183616512.0000 - val_loss: 8211457536.0000\n",
      "Epoch 1368/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7382253568.0000 - val_loss: 12425772032.0000\n",
      "Epoch 1369/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7350307328.0000 - val_loss: 8346833920.0000\n",
      "Epoch 1370/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7347079680.0000 - val_loss: 8295056384.0000\n",
      "Epoch 1371/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7350525952.0000 - val_loss: 8200646656.0000\n",
      "Epoch 1372/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7296956416.0000 - val_loss: 8993469440.0000\n",
      "Epoch 1373/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7198550528.0000 - val_loss: 8101934592.0000\n",
      "Epoch 1374/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7184511488.0000 - val_loss: 8099396096.0000\n",
      "Epoch 1375/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7231576576.0000 - val_loss: 8152056832.0000\n",
      "Epoch 1376/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7469119488.0000 - val_loss: 8091988992.0000\n",
      "Epoch 1377/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7107685376.0000 - val_loss: 8212881920.0000\n",
      "Epoch 1378/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7133869568.0000 - val_loss: 8093078016.0000\n",
      "Epoch 1379/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7398592512.0000 - val_loss: 8159195136.0000\n",
      "Epoch 1380/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7208266752.0000 - val_loss: 8961847296.0000\n",
      "Epoch 1381/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7186403840.0000 - val_loss: 7998116864.0000\n",
      "Epoch 1382/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7167751168.0000 - val_loss: 8372434432.0000\n",
      "Epoch 1383/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7230943744.0000 - val_loss: 8124616704.0000\n",
      "Epoch 1384/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7175623168.0000 - val_loss: 8013680128.0000\n",
      "Epoch 1385/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7371380736.0000 - val_loss: 8312090624.0000\n",
      "Epoch 1386/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7495894016.0000 - val_loss: 8259824128.0000\n",
      "Epoch 1387/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7124728832.0000 - val_loss: 8716483584.0000\n",
      "Epoch 1388/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7144292352.0000 - val_loss: 8291576320.0000\n",
      "Epoch 1389/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7236206592.0000 - val_loss: 8922872832.0000\n",
      "Epoch 1390/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7138761216.0000 - val_loss: 8244404736.0000\n",
      "Epoch 1391/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7244354048.0000 - val_loss: 8175083520.0000\n",
      "Epoch 1392/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7761535488.0000 - val_loss: 8750648320.0000\n",
      "Epoch 1393/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7326438912.0000 - val_loss: 8155641344.0000\n",
      "Epoch 1394/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7326114304.0000 - val_loss: 8250452992.0000\n",
      "Epoch 1395/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7124458496.0000 - val_loss: 8227352576.0000\n",
      "Epoch 1396/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7132261376.0000 - val_loss: 8503277568.0000\n",
      "Epoch 1397/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7210473984.0000 - val_loss: 8189098496.0000\n",
      "Epoch 1398/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7222488576.0000 - val_loss: 8570515456.0000\n",
      "Epoch 1399/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7169707520.0000 - val_loss: 8120712704.0000\n",
      "Epoch 1400/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7134680064.0000 - val_loss: 8131732992.0000\n",
      "Epoch 1401/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7383989760.0000 - val_loss: 8460465664.0000\n",
      "Epoch 1402/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179378176.0000 - val_loss: 8134046208.0000\n",
      "Epoch 1403/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7296169984.0000 - val_loss: 8227630592.0000\n",
      "Epoch 1404/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7264766464.0000 - val_loss: 7992629248.0000\n",
      "Epoch 1405/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 7135816704.0000 - val_loss: 8117954560.0000\n",
      "Epoch 1406/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7060263424.0000 - val_loss: 8085095424.0000\n",
      "Epoch 1407/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7193382400.0000 - val_loss: 8086854656.0000\n",
      "Epoch 1408/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7185693184.0000 - val_loss: 9078477824.0000\n",
      "Epoch 1409/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7228803072.0000 - val_loss: 8365549056.0000\n",
      "Epoch 1410/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7293389824.0000 - val_loss: 8418404352.0000\n",
      "Epoch 1411/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7309163520.0000 - val_loss: 8075506688.0000\n",
      "Epoch 1412/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7100404736.0000 - val_loss: 8147418624.0000\n",
      "Epoch 1413/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7291995648.0000 - val_loss: 8606584832.0000\n",
      "Epoch 1414/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7670910464.0000 - val_loss: 8054158336.0000\n",
      "Epoch 1415/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7183599616.0000 - val_loss: 8164890112.0000\n",
      "Epoch 1416/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7083606016.0000 - val_loss: 8298736640.0000\n",
      "Epoch 1417/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7130913280.0000 - val_loss: 8304056320.0000\n",
      "Epoch 1418/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7298851840.0000 - val_loss: 8606897152.0000\n",
      "Epoch 1419/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7213378048.0000 - val_loss: 8770530304.0000\n",
      "Epoch 1420/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7325127680.0000 - val_loss: 8283825152.0000\n",
      "Epoch 1421/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7254413312.0000 - val_loss: 8048253440.0000\n",
      "Epoch 1422/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7403825664.0000 - val_loss: 8841000960.0000\n",
      "Epoch 1423/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7079995392.0000 - val_loss: 8301374976.0000\n",
      "Epoch 1424/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7341832192.0000 - val_loss: 8135746048.0000\n",
      "Epoch 1425/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7411018752.0000 - val_loss: 8058416640.0000\n",
      "Epoch 1426/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7108880896.0000 - val_loss: 8168584192.0000\n",
      "Epoch 1427/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7309812736.0000 - val_loss: 8217086464.0000\n",
      "Epoch 1428/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7261285888.0000 - val_loss: 8552522240.0000\n",
      "Epoch 1429/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7159980032.0000 - val_loss: 8543629312.0000\n",
      "Epoch 1430/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7265055744.0000 - val_loss: 8038276608.0000\n",
      "Epoch 1431/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7081304064.0000 - val_loss: 8048275968.0000\n",
      "Epoch 1432/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7232887296.0000 - val_loss: 8540660224.0000\n",
      "Epoch 1433/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7183148544.0000 - val_loss: 8003186688.0000\n",
      "Epoch 1434/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7413153792.0000 - val_loss: 8069262848.0000\n",
      "Epoch 1435/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7231327744.0000 - val_loss: 8776823808.0000\n",
      "Epoch 1436/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7134057984.0000 - val_loss: 8479862272.0000\n",
      "Epoch 1437/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7500233728.0000 - val_loss: 8317557760.0000\n",
      "Epoch 1438/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7232408576.0000 - val_loss: 8107697152.0000\n",
      "Epoch 1439/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7394076672.0000 - val_loss: 7992549888.0000\n",
      "Epoch 1440/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7242433024.0000 - val_loss: 8196489728.0000\n",
      "Epoch 1441/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7178067968.0000 - val_loss: 8772895744.0000\n",
      "Epoch 1442/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7200851968.0000 - val_loss: 8320445952.0000\n",
      "Epoch 1443/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7244806144.0000 - val_loss: 8152802816.0000\n",
      "Epoch 1444/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7186162688.0000 - val_loss: 8070434816.0000\n",
      "Epoch 1445/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7284311040.0000 - val_loss: 8635621376.0000\n",
      "Epoch 1446/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7264856064.0000 - val_loss: 8369277952.0000\n",
      "Epoch 1447/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7155458560.0000 - val_loss: 8236490240.0000\n",
      "Epoch 1448/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7242845696.0000 - val_loss: 8016920064.0000\n",
      "Epoch 1449/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7140526080.0000 - val_loss: 8204767744.0000\n",
      "Epoch 1450/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7074595840.0000 - val_loss: 8004457984.0000\n",
      "Epoch 1451/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7163096064.0000 - val_loss: 8107551744.0000\n",
      "Epoch 1452/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7124951552.0000 - val_loss: 8110173184.0000\n",
      "Epoch 1453/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7196222464.0000 - val_loss: 9273190400.0000\n",
      "Epoch 1454/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7106928640.0000 - val_loss: 8248964096.0000\n",
      "Epoch 1455/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7270166528.0000 - val_loss: 8035205120.0000\n",
      "Epoch 1456/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7081878016.0000 - val_loss: 8003670016.0000\n",
      "Epoch 1457/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7121603584.0000 - val_loss: 8127495680.0000\n",
      "Epoch 1458/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7335868928.0000 - val_loss: 9104832512.0000\n",
      "Epoch 1459/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7391417856.0000 - val_loss: 8375502848.0000\n",
      "Epoch 1460/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7271581184.0000 - val_loss: 8104548864.0000\n",
      "Epoch 1461/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7372422144.0000 - val_loss: 8119220736.0000\n",
      "Epoch 1462/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7091913216.0000 - val_loss: 8230349312.0000\n",
      "Epoch 1463/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7172554752.0000 - val_loss: 9287497728.0000\n",
      "Epoch 1464/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7314448384.0000 - val_loss: 8012469248.0000\n",
      "Epoch 1465/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7217044480.0000 - val_loss: 8093167616.0000\n",
      "Epoch 1466/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7072879616.0000 - val_loss: 8054867456.0000\n",
      "Epoch 1467/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7355164672.0000 - val_loss: 8008310272.0000\n",
      "Epoch 1468/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7187609088.0000 - val_loss: 8035308544.0000\n",
      "Epoch 1469/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7191540224.0000 - val_loss: 8166615040.0000\n",
      "Epoch 1470/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7235093504.0000 - val_loss: 8814565376.0000\n",
      "Epoch 1471/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7231663104.0000 - val_loss: 8293567488.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1472/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7143689728.0000 - val_loss: 8171961856.0000\n",
      "Epoch 1473/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7365117952.0000 - val_loss: 8254872064.0000\n",
      "Epoch 1474/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7340444160.0000 - val_loss: 9352366080.0000\n",
      "Epoch 1475/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7142491648.0000 - val_loss: 8008626176.0000\n",
      "Epoch 1476/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7127325184.0000 - val_loss: 8199418880.0000\n",
      "Epoch 1477/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7489284608.0000 - val_loss: 8109157376.0000\n",
      "Epoch 1478/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7176980480.0000 - val_loss: 8031336448.0000\n",
      "Epoch 1479/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7215687680.0000 - val_loss: 8282926080.0000\n",
      "Epoch 1480/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7617035776.0000 - val_loss: 8138293760.0000\n",
      "Epoch 1481/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7239116288.0000 - val_loss: 8842513408.0000\n",
      "Epoch 1482/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7075418112.0000 - val_loss: 8222962688.0000\n",
      "Epoch 1483/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7298035200.0000 - val_loss: 8146822656.0000\n",
      "Epoch 1484/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7101017088.0000 - val_loss: 8094498816.0000\n",
      "Epoch 1485/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7122096640.0000 - val_loss: 8855565312.0000\n",
      "Epoch 1486/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7044050432.0000 - val_loss: 8531655168.0000\n",
      "Epoch 1487/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7157684224.0000 - val_loss: 8486998528.0000\n",
      "Epoch 1488/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7253513728.0000 - val_loss: 8537811456.0000\n",
      "Epoch 1489/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7193004032.0000 - val_loss: 8107420160.0000\n",
      "Epoch 1490/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136160768.0000 - val_loss: 8097567232.0000\n",
      "Epoch 1491/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7376421376.0000 - val_loss: 8649363456.0000\n",
      "Epoch 1492/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7143115264.0000 - val_loss: 8114406400.0000\n",
      "Epoch 1493/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7400040960.0000 - val_loss: 9372875776.0000\n",
      "Epoch 1494/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7264964096.0000 - val_loss: 8129437184.0000\n",
      "Epoch 1495/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7262012928.0000 - val_loss: 8114439168.0000\n",
      "Epoch 1496/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7079966720.0000 - val_loss: 8103126016.0000\n",
      "Epoch 1497/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7179072000.0000 - val_loss: 8020563968.0000\n",
      "Epoch 1498/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7136844288.0000 - val_loss: 8057314304.0000\n",
      "Epoch 1499/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7246360064.0000 - val_loss: 8172444672.0000\n",
      "Epoch 1500/1500\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 7269626880.0000 - val_loss: 8043788288.0000\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 19)                1558      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,098\n",
      "Trainable params: 3,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "deb136a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c20a4cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a08c2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ddb4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3163fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "170ad69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277068943626222"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68e5b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84828.7155787886"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (mean_squared_error(tahmin,y))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ade6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
